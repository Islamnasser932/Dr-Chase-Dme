import streamlit as st
import pandas as pd
import altair as alt
import re
from streamlit_option_menu import option_menu
from streamlit_extras.metric_cards import style_metric_cards

# ================== PAGE CONFIG ==================
st.set_page_config(
Â  Â  page_title="DR Chase Leads Dashboard",
Â  Â  page_icon="ğŸ“Š",
Â  Â  layout="wide",
Â  Â  initial_sidebar_state="expanded"
)

# ================== SIDEBAR MENU ==================
with st.sidebar:
Â  Â  selected = option_menu(
Â  Â  Â  Â  menu_title="Main Menu",
Â  Â  Â  Â  options=["Dataset Overview", "Data Analysis"],
Â  Â  Â  Â  icons=["table", "bar-chart"],
Â  Â  Â  Â  menu_icon="cast",
Â  Â  Â  Â  default_index=0,
Â  Â  Â  Â  orientation="vertical"
Â  Â  )

# ================== LOAD DATA ==================
df = pd.read_csv("Dr_Chase_Leads.csv", low_memory=False)
df.columns = df.columns.str.strip()

st.success("âœ… File loaded successfully!")

# ================== HELPER FUNCTIONS ==================
def norm(s: str) -> str:
Â  Â  return re.sub(r'[^a-z0-9]+', '', str(s).strip().lower())

def find_col(df_cols, candidates):
Â  Â  cand_norm = {norm(c) for c in candidates}
Â  Â  for c in df_cols:
Â  Â  Â  Â  if norm(c) in cand_norm:
Â  Â  Â  Â  Â  Â  return c
Â  Â  return None


# ================== SYNONYMS ==================
syn = {
Â  Â  "created_time": ["created_time", "created time", "creation time", "created", "lead created", "request created"],
Â  Â  "assign_date": ["assign_date", "assigned date", "assign time", "assigned time", "assigned on"],
Â  Â  "approval_date": ["approval_date", "approved date", "approval time", "approved on"],
Â  Â  "completion_date": ["completion_date", "completed date", "completion time", "closed date", "completed on"],
Â  Â  "uploaded_date": ["uploaded_date", "upload date", "uploaded date", "uploaded on"],
Â  Â  "assigned_to_chase": ["assigned to chase", "assigned_to_chase", "assigned to", "assigned user (chase)", "assigned chaser"],
}

cols_map = {
Â  Â  "created_time": find_col(df.columns, syn["created_time"]),
Â  Â  "assign_date": find_col(df.columns, syn["assign_date"]),
Â  Â  "approval_date": find_col(df.columns, syn["approval_date"]),
Â  Â  "completion_date": find_col(df.columns, syn["completion_date"]),
Â  Â  "uploaded_date": find_col(df.columns, syn["uploaded_date"]),
Â  Â  "assigned_to_chase": find_col(df.columns, syn["assigned_to_chase"]),
}

# ================== CLEAN DATA ==================
columns_to_remove = [
Â  Â  "Is Converted From Lead", "Height", "Weight", "Waist Size", "Dr Phone Number", "Dr Fax",
Â  Â  "Dr Alternative Phone", "Dr Address", "Dr City", "Dr ZIP Code", "NPI", "Dr Info Extra Comments",
Â  Â  "Dr. Name", "Exception", "Initial Agent", "Full Name", "Last Name", "Secondary Phone", "Address",
Â  Â  "Gender", "ZIP Code", "City", "Phase","First Name","LOMN?","Source","Brace Size","Extra Comments" ,"CBA","Primary Phone"
]
df_cleaned = df.drop(columns=[c for c in columns_to_remove if c in df.columns], errors="ignore")

date_columns = [
Â  Â  "Created Time", "Assigned date", "Completion Date", "Approval date",
Â  Â  "Denial Date", "Modified Time", "Date of Sale", "Upload Date",Â 
]

for col in date_columns:
Â  Â  if col in df_cleaned.columns:
Â  Â  Â  Â  # Convert to datetime (day first format)
Â  Â  Â  Â  df_cleaned[col] = pd.to_datetime(df_cleaned[col], errors="coerce", dayfirst=True)

Â  Â  Â  Â  # Create additional split columns for better readability
Â  Â  Â  Â  df_cleaned[col + " (Date)"] = df_cleaned[col].dt.date
Â  Â  Â  Â  if df_cleaned[col].dt.time.notna().any():Â  # only if time part exists
Â  Â  Â  Â  Â  Â  df_cleaned[col + " (Time)"] = df_cleaned[col].dt.time

# ================== NAME MAP ==================
name_map = {
Â  Â  "a.williams": "Alfred Williams",
Â  Â  "david.smith": "David Smith",
Â  Â  "jimmy.daves": "Grayson Saint",
Â  Â  "e.moore": "Eddie Moore",
Â  Â  "aurora.stevens": "Aurora Stevens",
Â  Â  "grayson.saint": "Grayson Saint",
Â  Â  "emma.wilson": "Emma Wilson",
Â  Â  "scarlett.mitchell": "Scarlett Mitchell",
Â  Â  "lucas.diago": "Lucas Diago",
Â  Â  "mia.alaxendar": "Mia Alaxendar",
Â  Â  "ivy.brooks": "Ivy Brooks",
Â  Â  "timothy.williams": "Timothy Williams",
Â  Â  "sarah.adams": "Sarah Adams",
Â  Â  "sara.adams": "Sarah Adams",
Â  Â  "samy.youssef": "Samy Youssef",
Â  Â  "candy.johns": "Candy Johns",
Â  Â  "heather.robertson": "Heather Robertson",
Â  Â  "a.cabello": "Andrew Cabello",
Â  Â  "alia.scott": "Alia Scott",
Â  Â  "sandra.sebastian": "Sandra Sebastian",
Â  Â  "kayla.miller": "Kayla Miller"
}

assigned_col = cols_map["assigned_to_chase"]
if assigned_col and assigned_col in df_cleaned.columns:
Â  Â  df_cleaned["Chaser Name"] = (
Â  Â  Â  Â  df_cleaned[assigned_col]
Â  Â  Â  Â  .astype(str).str.strip().str.lower()
Â  Â  Â  Â  .map(name_map)
Â  Â  Â  Â  .fillna(df_cleaned[assigned_col])
Â  Â  )

Â  Â  samy_chasers = {
Â  Â  Â  Â  "Emma Wilson", "Scarlett Mitchell", "Lucas Diago", "Mia Alaxendar",
Â  Â  Â  Â  "Candy Johns", "Sandra Sebastian", "Alia Scott",
Â  Â  Â  Â  "Ivy Brooks", "Heather Robertson", "Samy Youssef",
Â  Â  Â  Â  "Sarah Adams", "Timothy Williams"
Â  Â  }
Â  Â  df_cleaned["Chaser Group"] = df_cleaned["Chaser Name"].apply(
Â  Â  Â  Â  lambda n: "Samy Chasers" if n in samy_chasers else "Andrew Chasers"
Â  Â  )

# Convert dates
date_actual_cols = [cols_map[k] for k in ["created_time","assign_date","approval_date","completion_date","uploaded_date"] if cols_map[k]]
for c in date_actual_cols:
Â  Â  df_cleaned[c] = pd.to_datetime(df_cleaned[c], errors="coerce")

# ================== COLUMN DESCRIPTIONS ==================
column_descriptions = {
Â  Â  "Assigned To Chase": "Username of the chaser assigned to the lead (mapped later to full names).",
Â  Â  "Dr Chase Lead Number": "Unique ID assigned to each lead in the DR Chase system.",
Â  Â  "Created Time": "Timestamp when the lead was first created.",
Â  Â  "Modified Time": "Timestamp of the most recent modification.",
Â  Â  "Source": "Where the lead originated (e.g., CRM, referral, etc.).",
Â  Â  "Brace Size": "Medical brace size requested or required (e.g., Small, Medium, Large).",
Â  Â  "Extra Comments": "Additional notes about the lead, such as waist size or doctor instructions.",
Â  Â  "Dr Name": "Name of the doctor associated with the lead.",
Â  Â  "Dr State": "State where the doctor is located.",
Â  Â  "Dr Specialty": "Doctorâ€™s medical specialty (e.g., Internal Medicine, Orthopedics).",
Â  Â  "Confirmation Call Type": "Type of call used to confirm details (e.g., Doctor Call, Patient Call).",
Â  Â  "Closer Name": "Agent responsible for closing the lead.",
Â  Â  "Team Leader": "Team Leader supervising the chaser/closer.",
Â  Â  "L Codes": "Medical billing or insurance codes associated with the product (e.g., L1852).",
Â  Â  "Client": "Client associated with the lead (e.g., PPO-Braces chasing).",
Â  Â  "CBA": "Zipcode classification or market quality indicator (e.g., Good Zipcode).",
Â  Â  "Validator": "Agent responsible for validating the lead details.",
Â  Â  "Validation": "Validation status of the lead (e.g., Valid, Invalid).",
Â  Â  "Next Follow-up Date": "Planned date for the next follow-up.",
Â  Â  "Follow Up Attempts": "Number of follow-up attempts made.",
Â  Â  "Validation Comments": "Notes left by validators during validation checks.",
Â  Â  "Chasing Disposition": "Final chasing result (e.g., Dead Lead, Successful Chase).",
Â  Â  "Type Of Sale": "Category of the lead (e.g., Normal Chase, Red Flag).",
Â  Â  "Why is it a red chase?": "Explanation for red chase categorization.",
Â  Â  "Supervisor": "Supervisor responsible for overseeing the team.",
Â  Â  "Initial Status Received On": "First status received from doctorâ€™s office or patient (e.g., Pending Fax).",
Â  Â  "Dr Office DB Updated?": "Whether the doctor office database was updated (Yes/No).",
Â  Â  "Pharmacy Name": "Pharmacy involved in the case (if applicable).",
Â  Â  "Completion Date": "Date when the lead was completed/closed.",
Â  Â  "CN?": "Indicates whether a CN (Certificate of Necessity) is present (Yes/No).",
Â  Â  "QA Agent": "Quality Assurance agent who checked the case.",
Â  Â  "Uploaded?": "Whether the required documents were uploaded (Yes/No).",
Â  Â  "Upload Date": "Date when documents were uploaded.",
Â  Â  "QA Comments": "Feedback or notes from QA agent.",
Â  Â  "Approval date": "Date when the lead was approved.",
Â  Â  "Denial Date": "Date when the lead was denied (if applicable).",
Â  Â  "Assigned date": "Date the lead was assigned to a chaser.",
Â  Â  "Days Spent As Pending QA": "Number of days lead stayed in Pending QA status.",
Â  Â  "Primary Phone": "Patientâ€™s primary phone number.",
Â  Â  "Date of Birth": "Patientâ€™s date of birth.",
Â  Â  "Date of Sale": "Date when the sale was confirmed.",
Â  Â  "Insurance": "Type of insurance associated with the lead (e.g., PPO).",
Â  Â  "MCN": "Medical Case Number associated with the patient/lead.",
Â  Â  "PPO ID -If any-": "Insurance PPO ID if available.",
Â  Â  "Products": "Products linked to the lead (e.g., braces, medical items).",
Â  Â  "State": "Patientâ€™s state of residence.",
Â  Â  "Chasing Comments": "Additional notes from chasers about follow-ups.",
Â  Â  "Primary Insurance": "Primary insurance provider (e.g., Medicare).",
Â  Â  "Last Modified By": "User who last modified the lead record.",
Â  Â  "Chaser Name": "Mapped name of the chaser assigned to the lead.",
Â  Â  "Chaser Group": "Group classification (e.g., Samy Chasers, Andrew Chasers)."
}

df_filtered = df_cleaned.copy()
#switcher

# ================== SIDEBAR FILTERS ==================
st.sidebar.header("ğŸ› Basic Filters")

with st.sidebar.expander("ğŸ‘¥ Client", expanded=False):
Â  Â  all_clients = df_cleaned["Client"].unique().tolist()
Â  Â  select_all_clients = st.checkbox("Select All Clients", value=True, key="all_clients")
Â  Â  if select_all_clients:
Â  Â  Â  Â  Client = st.multiselect("Select Client", options=all_clients, default=all_clients)
Â  Â  else:
Â  Â  Â  Â  Client = st.multiselect("Select Client", options=all_clients)


with st.sidebar.expander("ğŸ§‘â€ğŸ’¼ Chaser Name", expanded=False):
Â  Â  all_Chaser_Name=df_cleaned["Chaser Name"].unique().tolist()
Â  Â  select_all_Chaser_Name = st.checkbox("Select All Chaser Name ", value=True, key="all_Chaser_Name")
Â  Â  if select_all_Chaser_Name:
Â  Â  Â  Â  Chaser_Name = st.multiselect("Select Chaser Name", options=all_Chaser_Name, default=all_Chaser_Name)Â  Â Â 
Â  Â  else:
Â  Â  Â  Â  Chaser_NameÂ  = st.multiselect("SelectÂ  Chaser Name ", options=all_Chaser_Name)
Â  Â  Â  Â  Â  Â  Â 

with st.sidebar.expander("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Chaser Group", expanded=False):
Â  Â  all_Chaser_Group=df_cleaned["Chaser Group"].unique().tolist()
Â  Â  select_all_Chaser_Group = st.checkbox("Select All Chaser Group ", value=True, key="all_Chaser_Group")
Â  Â  if select_all_Chaser_Group:
Â  Â  Â  Â  Chaser_Group = st.multiselect("Select Chaser Group", options=all_Chaser_Group, default=all_Chaser_Group)Â  Â Â 
Â  Â  else:
Â  Â  Â  Â  Chaser_GroupÂ  = st.multiselect("SelectÂ  Chaser Group ", options=all_Chaser_Group)


with st.sidebar.expander("ğŸ‘¥ Chasing Disposition", expanded=False):
Â  Â  all_Chasing_Disposition=df_cleaned["Chasing Disposition"].unique().tolist()
Â  Â  select_all_Chasing_Disposition = st.checkbox("Select All Chaser Disposition ", value=True, key="all_Chasing_Disposition")
Â  Â  if select_all_Chasing_Disposition:
Â  Â  Â  Â  Chasing_Disposition = st.multiselect("Select Chaser Disposition", options=all_Chasing_Disposition, default=all_Chasing_Disposition)Â  Â Â 
Â  Â  else:
Â  Â  Â  Â  Chasing_DispositionÂ  = st.multiselect("SelectÂ  Chaser Disposition ", options=all_Chasing_Disposition)


Â  Â Â 
with st.sidebar.expander("ğŸ“… Date Range", expanded=False):
Â  Â  min_date = pd.to_datetime(df_cleaned[date_columns].min().min()).date()
Â  Â  max_date = pd.to_datetime(df_cleaned[date_columns].max().max()).date()

Â  Â  date_range = st.date_input(
Â  Â  Â  Â  "Select date range",
Â  Â  Â  Â  value=(min_date, max_date),
Â  Â  Â  Â  min_value=min_date,
Â  Â  Â  Â  max_value=max_date
Â  Â  )
Â  Â Â 

# --- Apply filters using .query() ---
df_filtered = df_cleaned.query(
Â  Â  "Client in @Client and `Chaser Name` in @Chaser_Name and `Chaser Group` in @Chaser_Group and `Chasing Disposition` in @Chasing_Disposition"
)

# Apply date filter (on Created Time by default, but you can change to Completion Date, etc.)
if isinstance(date_range, tuple) and len(date_range) == 2:
Â  Â  start_date, end_date = date_range
Â  Â  if "Created Time" in df_filtered.columns:
Â  Â  Â  Â  df_filtered = df_filtered[
Â  Â  Â  Â  Â  Â  (df_filtered["Created Time"].dt.date >= start_date)
Â  Â  Â  Â  Â  Â  & (df_filtered["Created Time"].dt.date <= end_date)
Â  Â  Â  Â  ]

# ================== MAIN DASHBOARD ==================
if selected == "Dataset Overview":
Â  Â  st.title("ğŸ“‹ Dataset Overview â€“ General Inspection")
Â  Â  st.info("This page is for **quick inspection** of the dataset, showing key metrics, summaries, and descriptions of columns.")

Â  Â  # --- Column filter ---
# --- Function for tabular view ---
Â  Â  def table(df_filtered):
Â  Â  Â  Â  with st.expander("ğŸ“Š Tabular"):
Â  Â  Â  Â  Â  Â  shwdata = st.multiselect(
Â  Â  Â  Â  Â  Â  Â  Â  "Filter Columns:",
Â  Â  Â  Â  Â  Â  Â  Â  df_filtered.columns,
Â  Â  Â  Â  Â  Â  Â  Â  default=["MCN","Chaser Name","Chaser Group","Date of Sale (Date)","Created Time (Date)","Assigned date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "Approval date (Date)","Denial Date (Date)","Completion Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "Upload Date (Date)","Client","Chasing Disposition","Insurance","Type Of Sale","Products"]Â  # show first 6 columns by default
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.dataframe(df_filtered[shwdata], use_container_width=True)

Â  Â  # --- Inside your DR Chase Leads app ---
Â  Â  if selected == "Dataset Overview":
Â  Â  Â  Â  st.subheader("ğŸ” Data Inspection")
Â  Â  Â  Â  st.markdown(f""" The dataset contains **{len(df_filtered)} rows**
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  and **{len(df_filtered.columns)} columns**.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """)
Â  Â  Â  Â  # Show tabular selector
Â  Â  Â  Â  table(df_filtered)

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  total_leads = len(df_filtered)

Â  Â  # --- KPIs Section ---
Â  Â  st.subheader("ğŸ“Œ Key Performance Indicators")
Â  Â Â 
Â  Â  # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠÙ… ---
Â  Â  total_leads = len(df_filtered)
Â  Â  total_completed = df_filtered["Completion Date"].notna().sum() if "Completion Date" in df_filtered.columns else 0
Â  Â  total_assigned = df_filtered["Assigned date"].notna().sum() if "Assigned date" in df_filtered.columns else 0
Â  Â  total_uploaded = df_filtered["Upload Date"].notna().sum() if "Upload Date" in df_filtered.columns else 0
Â  Â  total_approval = df_filtered["Approval date"].notna().sum() if "Approval date" in df_filtered.columns else 0
Â  Â  total_denial = df_filtered["Denial Date"].notna().sum() if "Denial Date" in df_filtered.columns else 0
Â  Â Â 
Â  Â  # Derived metrics
Â  Â  total_not_assigned = total_leads - total_assigned
Â  Â Â 
Â  Â  # Percentages
Â  Â  pct_completed = (total_completed / total_leads * 100) if total_leads > 0 else 0
Â  Â  pct_assigned = (total_assigned / total_leads * 100) if total_leads > 0 else 0
Â  Â  pct_not_assigned = (total_not_assigned / total_leads * 100) if total_leads > 0 else 0
Â  Â  pct_uploaded = (total_uploaded / total_completed * 100) if total_completed > 0 else 0
Â  Â  pct_approval = (total_approval / total_leads * 100) if total_leads > 0 else 0
Â  Â  pct_denial = (total_denial / total_leads * 100) if total_leads > 0 else 0
Â  Â Â 
Â  Â  # --- KPIs Layout (ØµÙÙŠÙ†) ---
Â  Â  col1, col2, col3 = st.columns(3)
Â  Â  col4, col5, col6 = st.columns(3)
Â  Â Â 
Â  Â  with col1:
Â  Â  Â  Â  st.metric("ğŸ“Š Total Leads", f"{total_leads:,}")
Â  Â  with col2:
Â  Â  Â  Â  st.metric("ğŸ§‘â€ğŸ’¼ Assigned", f"{total_assigned:,} ({pct_assigned:.1f}%)")
Â  Â  with col3:
Â  Â  Â  Â  st.metric("âœ… Completed", f"{total_completed:,} ({pct_completed:.1f}%)")
Â  Â  with col4:
Â  Â  Â  Â  st.metric("âœ” Approved / âŒ Denied", f"{total_approval:,} ({pct_approval:.1f}%) / {total_denial:,} ({pct_denial:.1f}%)")
Â  Â  with col5:
Â  Â  Â  Â  st.metric("ğŸš« Not Assigned", f"{total_not_assigned:,} ({pct_not_assigned:.1f}%)")Â 
Â  Â  with col6:
Â  Â  Â  Â  st.metric("ğŸ“¤ Uploaded", f"{total_uploaded:,} ({pct_uploaded:.1f}%)")
Â  Â  Â  Â Â 
Â  Â Â 
Â  Â  Â  Â  # âœ… Apply custom style
Â  Â  style_metric_cards(
Â  Â  Â  Â  background_color="#0E1117",Â  Â # Ø®Ù„ÙÙŠØ© dashboard ØºØ§Ù…Ù‚Ø©
Â  Â  Â  Â  border_left_color="#00BFFF",Â  # Ø£Ø²Ø±Ù‚ Ù„Ù„Ù€ Total
Â  Â  Â  Â  border_color="#444",
Â  Â  Â  Â  box_shadow="2px 2px 10px rgba(0,0,0,0.5)"
Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â Â 
Â  Â Â 
Â  Â Â 
Â  Â  # --- Dates summary (table) ---
Â  Â  date_cols = df_filtered.select_dtypes(include=["datetime64[ns]"]).columns
Â  Â  if len(date_cols) > 0:
Â  Â  Â  Â  st.markdown("### ğŸ“… Date Ranges in Dataset")
Â  Â  Â  Â  date_summary = pd.DataFrame({
Â  Â  Â  Â  Â  Â  "Column": date_cols,
Â  Â  Â  Â  Â  Â  "First Date": [df_filtered[c].min() for c in date_cols],
Â  Â  Â  Â  Â  Â  "Last Date": [df_filtered[c].max() for c in date_cols],
Â  Â  Â  Â  })
Â  Â  Â  Â  st.table(date_summary)


Â  Â  # --- Numeric summary (table) ---
Â  Â  num_cols = df_filtered.select_dtypes(include=["int64", "float64"]).columns
Â  Â  if len(num_cols) > 0:
Â  Â  Â  Â  st.markdown("### ğŸ”¢ Numeric Columns Summary")
Â  Â  Â  Â  num_summary = pd.DataFrame({
Â  Â  Â  Â  Â  Â  "Column": num_cols,
Â  Â  Â  Â  Â  Â  "Min": [df_filtered[c].min() for c in num_cols],
Â  Â  Â  Â  Â  Â  "Max": [df_filtered[c].max() for c in num_cols],
Â  Â  Â  Â  Â  Â  "Mean": [round(df_filtered[c].mean(), 2) for c in num_cols]
Â  Â  Â  Â  })
Â  Â  Â  Â  st.table(num_summary)

Â  Â  # --- Column Descriptions ---
Â  Â  st.subheader("ğŸ“– Column Descriptions")
Â  Â  st.info("Choose a column to see what it represents and explore its distribution.")

Â  Â  Â  Â  # âœ… Restrict to specific columns
Â  Â  description_columns = [
Â  Â  Â  Â  "Chaser Name", "Chaser Group", "Date of Sale (Date)", "Created Time (Date)",
Â  Â  Â  Â  "Assigned date (Date)", "Approval date (Date)", "Denial Date (Date)",
Â  Â  Â  Â  "Completion Date (Date)", "Upload Date (Date)", "Client",
Â  Â  Â  Â  "Chasing Disposition", "Insurance", "Type Of Sale", "Products","Days Spent As Pending QA"
Â  Â  ]

Â  Â  # Keep only the ones that exist in df_cleaned
Â  Â  valid_desc_cols = [c for c in description_columns if c in df_cleaned.columns]

Â  Â  selected_col = st.selectbox(
Â  Â  Â  Â  "Select a column to view description",
Â  Â  Â  Â  valid_desc_cols
Â  Â  )

Â  Â  # Provide actual descriptions
Â  Â  column_descriptions = {
Â  Â  Â  Â  "Chaser Name": " chaser Name assigned to the lead.",
Â  Â  Â  Â  "Chaser Group": "Group classification (Samy Chasers or Andrew Chasers).",
Â  Â  Â  Â  "Date of Sale (Date)": "The confirmed sale date of the lead.",
Â  Â  Â  Â  "Created Time (Date)": "When the lead was created.",
Â  Â  Â  Â  "Assigned date (Date)": "When the lead was assigned to a chaser.",
Â  Â  Â  Â  "Approval date (Date)": "When the lead was approved.",
Â  Â  Â  Â  "Denial Date (Date)": "When the lead was denied.",
Â  Â  Â  Â  "Completion Date (Date)": "When the lead was completed.",
Â  Â  Â  Â  "Upload Date (Date)": "When documents were uploaded.",
Â  Â  Â  Â  "Client": "Client associated with the lead (e.g., PPO-Braces chasing).",
Â  Â  Â  Â  "Chasing Disposition": "Final chasing result (e.g., Dead Lead, Successful Chase).",
Â  Â  Â  Â  "Insurance": "Insurance provider associated with the patient.",
Â  Â  Â  Â  "Type Of Sale": "Category of the lead (e.g., Normal Chase, Red Flag).",
Â  Â  Â  Â  "Products": "Products linked to the lead (e.g., braces, medical items).",
Â  Â  Â  Â  "Days Spent As Pending QA": "Number of days lead stayed in Pending QA status."
Â  Â  }

Â  Â  desc = column_descriptions.get(selected_col, "No description available for this column.")
Â  Â Â 

Â  Â  # --- Force date conversion for known date columns ---
Â  Â  date_columns = [
Â  Â  Â  Â  "Date of Sale (Date)", "Created Time (Date)", "Assigned date (Date)",
Â  Â  Â  Â  "Approval date (Date)", "Denial Date (Date)",
Â  Â  Â  Â  "Completion Date (Date)", "Upload Date (Date)"
Â  Â  ]

Â  Â  for col in date_columns:
Â  Â  Â  Â  if col in df_filtered.columns:
Â  Â  Â  Â  Â  Â  df_filtered[col] = pd.to_datetime(df_filtered[col], errors="coerce")

Â  Â  # --- Extra Visualization (same logic you already have) ---
Â  Â  if selected_col in df_filtered.select_dtypes(include=["object"]).columns:
Â  Â  Â  Â  st.markdown(f"### ğŸ“Š Distribution of {selected_col}")
Â  Â  Â  Â  chart_data = df_filtered[selected_col].value_counts().reset_index()
Â  Â  Â  Â  chart_data.columns = [selected_col, "Count"]

Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  alt.Chart(chart_data)
Â  Â  Â  Â  Â  Â  .mark_bar(color="#16eff7")
Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X(selected_col, sort="-y"),
Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[selected_col, "Count"]
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)

Â  Â  elif selected_col in df_filtered.select_dtypes(include=["number"]).columns:
Â  Â  Â  Â  st.markdown(f"### ğŸ“Š Distribution of {selected_col}")

Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  alt.Chart(df_filtered)
Â  Â  Â  Â  Â  Â  .mark_bar(color="#0eff87")
Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X(selected_col, bin=alt.Bin(maxbins=30)),Â  # bins for histogram
Â  Â  Â  Â  Â  Â  Â  Â  y='count()',
Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[selected_col, "count()"]
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)




Â  Â  elif selected_col in df_filtered.select_dtypes(include=["datetime64[ns]"]).columns:
Â  Â  Â  Â  st.markdown(f"### ğŸ“ˆ Time Series of {selected_col}")
Â  Â  Â  Â  ts_data = df_filtered[selected_col].value_counts().reset_index()
Â  Â  Â  Â  ts_data.columns = [selected_col, "Count"]
Â  Â  Â  Â  ts_data = ts_data.sort_values(selected_col)

Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  alt.Chart(ts_data)
Â  Â  Â  Â  Â  Â  .mark_line(point=True, color="#ff7f0e")
Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  x=selected_col,
Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[selected_col, "Count"]
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)



elif selected == "Data Analysis":
Â  Â  st.title("ğŸ“Š Data Analysis â€“ Advanced Insights")
Â  Â  st.info("This page provides **deeper analysis** including time-series trends, insights summaries, and lead age analysis by Chaser / Client.")

Â  Â  # --- Allowed columns for analysis ---
Â  Â  allowed_columns = [
Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  "Assigned date (Date)",
Â  Â  Â  Â  "Approval date (Date)",
Â  Â  Â  Â  "Denial Date (Date)",
Â  Â  Â  Â  "Completion Date (Date)",
Â  Â  Â  Â  "Upload Date (Date)",
Â  Â  Â  Â  "Date of Sale (Date)",
Â  Â  ]
Â  Â Â 
Â  Â  # Keep only available ones from dataset
Â  Â  available_columns = [c for c in allowed_columns if c in df_filtered.columns]
Â  Â Â 
Â  Â  if not available_columns:
Â  Â  Â  Â  st.warning("âš ï¸ None of the predefined analysis columns are available in the dataset.")
Â  Â  else:
Â  Â  Â  Â  time_col = st.selectbox("Select column for analysis", available_columns)
Â  Â Â 
Â  Â  Â  Â  # Convert to datetime if column looks like a date
Â  Â  Â  Â  if "date" in time_col.lower():
Â  Â  Â  Â  Â  Â  df_filtered[time_col] = pd.to_datetime(df_filtered[time_col], errors="coerce", dayfirst=True)
Â  Â Â 
Â  Â  Â  Â  Â  Â  today = pd.Timestamp.now().normalize()
Â  Â  Â  Â  Â  Â  future_mask = df_filtered[time_col] > today
Â  Â  Â  Â  Â  Â  if future_mask.any():
Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Detected {future_mask.sum()} rows with future {time_col} values.")
Â  Â  Â  Â  Â  Â  Â  Â  if st.checkbox("Show rows with future dates"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(df_filtered.loc[future_mask])
Â  Â Â 
Â  Â  Â  Â  Â  Â  df_ts = df_filtered.loc[~future_mask].copy()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  df_ts = df_filtered.copy()

Â  Â  # --- Function for tabular view ---
Â  Â  def table(df_filtered):
Â  Â  Â  Â  with st.expander("ğŸ“Š Tabular"):
Â  Â  Â  Â  Â  Â  shwdata = st.multiselect(
Â  Â  Â  Â  Â  Â  Â  Â  "Filter Columns:",
Â  Â  Â  Â  Â  Â  Â  Â  df_filtered.columns,
Â  Â  Â  Â  Â  Â  Â  Â  default=["MCN","Chaser Name","Chaser Group","Date of Sale (Date)","Created Time (Date)","Assigned date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "Approval date (Date)","Denial Date (Date)","Completion Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â "Upload Date (Date)","Client","Chasing Disposition","Insurance","Type Of Sale","Products"]Â  # show first 6 columns by default
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.dataframe(df_filtered[shwdata], use_container_width=True)

Â  Â  # --- Inside your DR Chase Leads app ---
Â  Â  if selected == "Data Analysis":
Â  Â  Â  Â  st.markdown(f""" The dataset contains **{len(df_filtered)} rows**
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  and **{len(df_filtered.columns)} columns**.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  """)
Â  Â  Â  Â  # Show tabular selector
Â  Â  Â  Â  table(df_filtered)

Â  Â  Â  Â  Â  Â  Â  Â Â 

Â  Â  total_leads = len(df_filtered)
Â Â 
Â  Â  # --- Aggregation frequency ---
Â  Â  freq = st.radio("Aggregation level:", ["Daily", "Weekly", "Monthly"], horizontal=True)
Â  Â  period_map = {"Daily": "D", "Weekly": "W", "Monthly": "M"}
Â  Â  df_ts["Period"] = df_ts[time_col].dt.to_period(period_map[freq]).dt.to_timestamp()

Â  Â  # --- Grouping option ---
Â  Â  group_by = st.selectbox("Break down by:", ["None", "Client", "Chaser Name", "Chaser Group"])
Â  Â  if group_by == "None":
Â  Â  Â  Â  ts_data = df_ts.groupby("Period").size().reset_index(name="Lead Count")
Â  Â  else:
Â  Â  Â  Â  ts_data = df_ts.groupby(["Period", group_by]).size().reset_index(name="Lead Count")

Â  Â  if not ts_data.empty:
Â  Â  Â  Â  # ğŸ“ˆ Historical Time Series
Â  Â  Â  Â  st.subheader("ğŸ“ˆ Historical Time Series")

Â  Â  Â  Â  if group_by == "None":
Â  Â  Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(ts_data)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_line(point=True, color="#007bff")
Â  Â  Â  Â  Â  Â  Â  Â  .encode(x="Period:T", y="Lead Count", tooltip=["Period:T", "Lead Count"])
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(ts_data)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_line(point=True)
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x="Period:T",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Lead Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=group_by,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Period:T", "Lead Count", group_by]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)


Â  Â  Â  Â  # ğŸ† Top performers
Â  Â  Â  Â  if group_by in ["Chaser Name", "Client"]:
Â  Â  Â  Â  Â  Â  st.subheader(f"ğŸ† Top {group_by}s by Leads")
Â  Â  Â  Â  Â  Â  top_table = ts_data.groupby(group_by)["Lead Count"].sum().reset_index()
Â  Â  Â  Â  Â  Â  top_table = top_table.sort_values("Lead Count", ascending=False).head(40)
Â  Â  Â  Â  Â  Â  st.table(top_table)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # ================== Chasing Disposition Distribution ==================
Â  Â  Â  Â  if "Chasing Disposition" in df_ts.columns:
Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“Š Chasing Disposition Distribution")

Â  Â  Â  Â  Â  Â  # --- Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø§Ù„Ù„ÙŠ Ù†Ø¹Ø±Ø¶Ù‡Ø§ ---
Â  Â  Â  Â  Â  Â  metric_option = st.selectbox(
Â  Â  Â  Â  Â  Â  Â  Â  "Select metric to display by Chasing Disposition:",
Â  Â  Â  Â  Â  Â  Â  Â  [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded"
Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø­Ø³Ø¨ ÙƒÙ„ Chasing Disposition ---
Â  Â  Â  Â  Â  Â  metrics_by_disp = df_ts.groupby("Chasing Disposition").agg({
Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)": "count",
Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Approval date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  }).reset_index()

Â  Â  Â  Â  Â  Â  metrics_by_disp["Not Assigned"] = (
Â  Â  Â  Â  Â  Â  Â  Â  metrics_by_disp["Created Time (Date)"] - metrics_by_disp["Assigned date"]
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # --- Ø±Ø¨Ø· Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø¨Ø§Ù„Ø§Ø¹Ù…Ø¯Ø© ---
Â  Â  Â  Â  Â  Â  metric_map = {
Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))": "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned": "Assigned date",
Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned": "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved": "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied": "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed": "Completion Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded": "Upload Date"
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  selected_col = metric_map[metric_option]

Â  Â  Â  Â  Â  Â  # --- Ø¬Ù‡Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
Â  Â  Â  Â  Â  Â  chart_data = metrics_by_disp[["Chasing Disposition", selected_col]].rename(columns={selected_col: "Count"})

Â  Â  Â  Â  Â  Â  # --- Bar chart only ---
Â  Â  Â  Â  Â  Â  chart_disp = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(chart_data)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Chasing Disposition", sort="-y"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Chasing Disposition",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Chasing Disposition", "Count"]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.altair_chart(chart_disp, use_container_width=True)


Â  Â  Â  Â  Â  Â  Â  Â  # ================== Client Distribution ==================
Â  Â  Â  Â  if "Client" in df_ts.columns:
Â  Â  Â  Â  Â  Â  st.subheader("ğŸ‘¥ Client Distribution")
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø§Ù„Ù„ÙŠ Ù†Ø¹Ø±Ø¶Ù‡Ø§ ---
Â  Â  Â  Â  Â  Â  metric_option = st.selectbox(
Â  Â  Â  Â  Â  Â  Â  Â  "Select metric to display by Client:",
Â  Â  Â  Â  Â  Â  Â  Â  [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded"
Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø­Ø³Ø¨ ÙƒÙ„ Client ---
Â  Â  Â  Â  Â  Â  metrics_by_client = df_ts.groupby("Client").agg({
Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)": "count",
Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Approval date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  }).reset_index()
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  metrics_by_client["Not Assigned"] = metrics_by_client["Created Time (Date)"] - metrics_by_client["Assigned date"]
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø±Ø¨Ø· Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø¨Ø§Ù„Ø§Ø¹Ù…Ø¯Ø© ---
Â  Â  Â  Â  Â  Â  metric_map = {
Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))": "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned": "Assigned date",
Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned": "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved": "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied": "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed": "Completion Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded": "Upload Date"
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  selected_col = metric_map[metric_option]
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø¬Ù‡Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
Â  Â  Â  Â  Â  Â  chart_data = metrics_by_client[["Client", selected_col]].rename(columns={selected_col: "Count"})
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  chart_disp = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(chart_data)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Client", sort="-y"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Client", "Count"]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.altair_chart(chart_disp, use_container_width=True)

Â  Â  Â  Â  # ğŸ“ Insights Summary
Â  Â  Â  Â  st.subheader("ğŸ“ Insights Summary")
Â  Â  Â  Â  st.info("High-level insights based on the selected date column: assigned, approvals, denials, and warnings if data is inconsistent.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  # --- Subset based on selected time_col ---
Â  Â  Â  Â  df_time = df_ts[df_ts[time_col].notna()].copy()
Â  Â  Â  Â  total_time_leads = len(df_time)
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.write(f"Based on **{time_col}**, there are **{total_time_leads} leads** with this date.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if total_time_leads > 0:
Â  Â  Â  Â  Â  Â  total_assigned = df_time["Assigned date"].notna().sum() if "Assigned date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_not_assigned = total_time_leads - total_assigned
Â  Â  Â  Â  Â  Â  total_approval = df_time["Approval date"].notna().sum() if "Approval date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_denial = df_time["Denial Date"].notna().sum() if "Denial Date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_uploaded = df_time["Upload Date"].notna().sum() if "Upload Date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_completed = df_time["Completion Date"].notna().sum() if "Completion Date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Show stats
Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  - âœ… Total Leads (with {time_col}): **{total_time_leads}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸ§‘â€ğŸ’¼ Assigned: **{total_assigned}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸš« Not Assigned: **{total_not_assigned}**
Â  Â  Â  Â  Â  Â  Â  Â  - âœ” Approved: **{total_approval}**
Â  Â  Â  Â  Â  Â  Â  Â  - âŒ Denied: **{total_denial}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸ“Œ Completed: **{total_completed}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸ“¤ Uploaded: **{total_uploaded}**
Â  Â  Â  Â  Â  Â  Â  Â  """)Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.subheader("ğŸš¨ Data Quality Warnings")
Â  Â  Â  Â  Â  Â  today = pd.Timestamp.now().normalize()


Â  Â  Â  Â  Â  Â  # ğŸš¨ Leads with Pending Shipping but no Upload Date
Â  Â  Â  Â  Â  Â  if "Chasing Disposition" in df_filtered.columns and "Upload Date" in df_filtered.columns:
Â  Â  Â  Â  Â  Â  Â  Â  mask_shipping = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_filtered["Chasing Disposition"].str.lower().eq("pending shipping")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  & df_filtered["Upload Date"].isna()
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  pending_shipping = df_filtered[mask_shipping]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if not pending_shipping.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(pending_shipping)} leads with **Pending Shipping** but missing **Upload Date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Pending Shipping Leads Without Upload Date"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pending_shipping[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chasing Disposition",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸš¨ Leads pending too long (Fax / Dr Call)
Â  Â  Â  Â  Â  Â  if "Created Time (Date)" in df_filtered.columns and "Chasing Disposition" in df_filtered.columns:
Â  Â  Â  Â  Â  Â  Â  Â  today = pd.Timestamp.now().normalize()
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  df_filtered["Days Since Created"] = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  today - pd.to_datetime(df_filtered["Created Time (Date)"], errors="coerce")
Â  Â  Â  Â  Â  Â  Â  Â  ).dt.days
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  pending_mask = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (df_filtered["Days Since Created"] > 7) &
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (df_filtered["Chasing Disposition"].isin(["Pending Fax", "Pending Dr Call"]))
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  pending_leads = df_filtered[pending_mask]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if not pending_leads.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(pending_leads)} leads pending for more than 7 days (Fax/Dr Call).")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Pending Leads > 7 Days"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pending_leads[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Days Since Created",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chasing Disposition",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )


Â  Â  Â  Â  Â  Â  # --- Row-level logic checks with expanders ---
Â  Â  Â  Â  Â  Â  if "Completion Date" in df_time.columns and "Assigned date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_rows = df_time[df_time["Completion Date"].notna() & df_time["Assigned date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_rows.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_rows)} leads with **Completion Date** but no **Assigned date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Assigned Date"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_rows[["MCN", "Client", "Chaser Name", "Created Time", "Assigned date", "Completion Date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if "Completion Date" in df_time.columns and "Approval date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_rows2 = df_time[df_time["Completion Date"].notna() & df_time["Approval date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_rows2.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_rows2)} leads with **Completion Date** but no **Approval date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Approval Date"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_rows2[["MCN", "Client", "Chaser Name", "Created Time", "Approval date", "Completion Date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Extra checks for Uploaded Date ---
Â  Â  Â  Â  Â  Â  if "Upload Date" in df_time.columns and "Completion Date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded = df_time[df_time["Upload Date"].notna() & df_time["Completion Date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_uploaded.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_uploaded)} leads with **Upload Date** but no **Completion Date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Completion Date after Upload"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded[["MCN", "Client", "Chaser Name", "Upload Date", "Completion Date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if "Upload Date" in df_time.columns and "Assigned date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_assigned = df_time[df_time["Upload Date"].notna() & df_time["Assigned date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_uploaded_assigned.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_uploaded_assigned)} leads with **Upload Date** but no **Assigned date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Assigned Date after Upload"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_assigned[["MCN", "Client", "Chaser Name", "Upload Date", "Assigned date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if "Upload Date" in df_time.columns and "Approval date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_approval = df_time[df_time["Upload Date"].notna() & df_time["Approval date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_uploaded_approval.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_uploaded_approval)} leads with **Upload Date** but no **Approval date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Approval Date after Upload"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_approval[["MCN", "Client", "Chaser Name", "Upload Date", "Approval date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )


Â  Â  Â  Â Â 
Â  Â  Â  Â  # ================== Lead Age Analysis ==================
Â  Â  st.subheader("â³ Lead Age Analysis")
Â  Â  st.info("Analysis of how long it takes for leads to get Approved / Denied. Includes weekly distribution, averages/medians, and grouped comparisons.")
Â  Â Â 
Â  Â  if "Created Time (Date)" in df_ts.columns:
Â  Â  Â  Â  df_lead_age = df_ts.copy()
Â  Â Â 
Â  Â  Â  Â  # Ø­Ø³Ø§Ø¨ Lead Age Ù…Ù† Approval Ùˆ Denial
Â  Â  Â  Â  if "Approval date" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  df_lead_age["Lead Age (Approval)"] = (
Â  Â  Â  Â  Â  Â  Â  Â  (df_lead_age["Approval date"] - df_lead_age["Created Time"]).dt.days
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  if "Denial Date" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  df_lead_age["Lead Age (Denial)"] = (
Â  Â  Â  Â  Â  Â  Â  Â  (df_lead_age["Denial Date"] - df_lead_age["Created Time"]).dt.days
Â  Â  Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  # --- KPIs Section ---
Â  Â  Â  Â  total_approved = df_lead_age["Approval date"].notna().sum()
Â  Â  Â  Â  total_denied = df_lead_age["Denial Date"].notna().sum()
Â  Â  Â  Â  avg_approval_age = df_lead_age["Lead Age (Approval)"].mean(skipna=True)
Â  Â  Â  Â  avg_denial_age = df_lead_age["Lead Age (Denial)"].mean(skipna=True)
Â  Â Â 
Â  Â  Â  Â  col1, col2, col3, col4 = st.columns(4)
Â  Â  Â  Â  with col1:
Â  Â  Â  Â  Â  Â  st.metric("âœ”ï¸ Total Approved", f"{total_approved:,}")
Â  Â  Â  Â  with col2:
Â  Â  Â  Â  Â  Â  st.metric("âŒ Total Denied", f"{total_denied:,}")
Â  Â  Â  Â  with col3:
Â  Â  Â  Â  Â  Â  st.metric("â³ Avg Approval Age", f"{avg_approval_age:.1f} days" if not pd.isna(avg_approval_age) else "N/A")
Â  Â  Â  Â  with col4:
Â  Â  Â  Â  Â  Â  st.metric("â³ Avg Denial Age", f"{avg_denial_age:.1f} days" if not pd.isna(avg_denial_age) else "N/A")
Â  Â Â 
Â  Â  Â  Â  style_metric_cards(
Â  Â  Â  Â  Â  Â  background_color="#0E1117",
Â  Â  Â  Â  Â  Â  border_left_color={
Â  Â  Â  Â  Â  Â  Â  Â  "âœ”ï¸ Total Approved": "#28a745",
Â  Â  Â  Â  Â  Â  Â  Â  "âŒ Total Denied": "#dc3545",
Â  Â  Â  Â  Â  Â  Â  Â  "â³ Avg Approval Age": "#17a2b8",
Â  Â  Â  Â  Â  Â  Â  Â  "â³ Avg Denial Age": "#ffc107",
Â  Â  Â  Â  Â  Â  },
Â  Â  Â  Â  Â  Â  border_color="#444",
Â  Â  Â  Â  Â  Â  box_shadow="2px 2px 10px rgba(0,0,0,0.5)"
Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  # ğŸ“‹ Full Lead Age Table (hidden by default)
Â  Â  Â  Â  with st.expander("ğŸ“‹ View Full Lead Age Table"):
Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Approval)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Denial)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  # --- Function to categorize weeks ---
Â  Â  Â  Â  import math
Â  Â  Â  Â  def categorize_weeks(days):
Â  Â  Â  Â  Â  Â  if pd.isna(days):
Â  Â  Â  Â  Â  Â  Â  Â  return None
Â  Â  Â  Â  Â  Â  if days >= 0:
Â  Â  Â  Â  Â  Â  Â  Â  return f"Week {math.floor(days / 7) + 1}"
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  return f"Week {math.ceil(days / 7)}"Â  Â # Week -1, Week -2 ...
Â  Â Â 
Â  Â  Â  Â  # ğŸš¨ Check for leads with both Approval & Denial
Â  Â  Â  Â  both_dates = df_lead_age[df_lead_age["Approval date"].notna() & df_lead_age["Denial Date"].notna()]
Â  Â  Â  Â  if not both_dates.empty:
Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(both_dates)} leads with BOTH Approval & Denial dates. Please review.")
Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads with BOTH Approval & Denial"):
Â  Â  Â  Â  Â  Â  Â  Â  cols_to_show = [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Approval)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Denial)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  available_cols = [c for c in cols_to_show if c in both_dates.columns]
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(both_dates[available_cols], use_container_width=True)
Â  Â Â 
Â  Â  Â  Â  # ğŸ“Š Lead Age Distribution â€“ Approval
Â  Â  Â  Â  if "Lead Age (Approval)" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“Š Lead Age Distribution â€“ Approval"):
Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Approval Category"] = df_lead_age["Lead Age (Approval)"].dropna().apply(categorize_weeks)
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  categories = df_lead_age["Approval Category"].dropna().unique()
Â  Â  Â  Â  Â  Â  Â  Â  weeks_negative = sorted([c for c in categories if "Week -" in c], key=lambda x: int(x.split()[1]))
Â  Â  Â  Â  Â  Â  Â  Â  weeks_positive = sorted([c for c in categories if "Week " in c and "-" not in c], key=lambda x: int(x.split()[1]))
Â  Â  Â  Â  Â  Â  Â  Â  category_order = weeks_negative + weeks_positive
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  approval_summary = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Approval Category"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .value_counts()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reindex(category_order)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reset_index()
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  approval_summary.columns = ["Category", "Count"]
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  approval_summary["Color"] = approval_summary["Category"].apply(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lambda x: "#FFA500" if "Week -" in x else "#28a745"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  chart_approval = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(approval_summary)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Category", sort=category_order),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=alt.Color("Color:N", scale=None, legend=None),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Category", "Count"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.altair_chart(chart_approval, use_container_width=True)
Â  Â  Â  Â  Â  Â  Â  Â  # Ø¬Ø¯ÙˆÙ„ leads ÙÙŠ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø³Ø§Ù„Ø¨Ø© - Approval
Â  Â  Â  Â  Â  Â  Â  Â  if "Approval Category" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_approval = df_lead_age[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Approval Category"].astype(str).str.contains("Week -", na=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not negative_approval.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(negative_approval)} approvals with negative week categories.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_approval[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Approval)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval Category",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â Â 
Â  Â  Â  Â  # ğŸ“Š Lead Age Distribution â€“ Denial
Â  Â  Â  Â  if "Lead Age (Denial)" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“Š Lead Age Distribution â€“ Denial"):
Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Denial Category"] = df_lead_age["Lead Age (Denial)"].dropna().apply(categorize_weeks)
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  categories = df_lead_age["Denial Category"].dropna().unique()
Â  Â  Â  Â  Â  Â  Â  Â  weeks_negative = sorted([c for c in categories if "Week -" in c], key=lambda x: int(x.split()[1]))
Â  Â  Â  Â  Â  Â  Â  Â  weeks_positive = sorted([c for c in categories if "Week " in c and "-" not in c], key=lambda x: int(x.split()[1]))
Â  Â  Â  Â  Â  Â  Â  Â  category_order = weeks_negative + weeks_positive
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  denial_summary = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Denial Category"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .value_counts()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reindex(category_order)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reset_index()
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  denial_summary.columns = ["Category", "Count"]
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  denial_summary["Color"] = denial_summary["Category"].apply(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lambda x: "#FFA500" if "Week -" in x else "#dc3545"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  chart_denial = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(denial_summary)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Category", sort=category_order),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=alt.Color("Color:N", scale=None, legend=None),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Category", "Count"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.altair_chart(chart_denial, use_container_width=True)
Â  Â  Â  Â  Â  Â  Â  Â  # Ø¬Ø¯ÙˆÙ„ leads ÙÙŠ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø³Ø§Ù„Ø¨Ø© - Denial
Â  Â  Â  Â  Â  Â  Â  Â  if "Denial Category" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_denial = df_lead_age[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Denial Category"].astype(str).str.contains("Week -", na=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not negative_denial.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(negative_denial)} denials with negative week categories.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_denial[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Denial)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Category",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â Â 
Â  Â  Â  Â  # ğŸ“Š Grouped Bar Chart â€“ Approval vs Denial per Chaser
Â  Â  Â  Â  if "Chaser Name" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ“Š Approval vs Denial Lead Age by Chaser")
Â  Â  Â  Â  Â  Â  grouped_chaser = pd.melt(
Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age,
Â  Â  Â  Â  Â  Â  Â  Â  id_vars=["Chaser Name"],
Â  Â  Â  Â  Â  Â  Â  Â  value_vars=["Lead Age (Approval)", "Lead Age (Denial)"],
Â  Â  Â  Â  Â  Â  Â  Â  var_name="Type",
Â  Â  Â  Â  Â  Â  Â  Â  value_name="Days"
Â  Â  Â  Â  Â  Â  ).dropna()
Â  Â Â 
Â  Â  Â  Â  Â  Â  chart_grouped_chaser = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(grouped_chaser)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x="Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="mean(Days)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Type",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Chaser Name", "Type", "mean(Days)"]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.altair_chart(chart_grouped_chaser, use_container_width=True)
Â  Â Â 
Â  Â  Â  Â  # ğŸ“Š Grouped Bar Chart â€“ Approval vs Denial per Client
Â  Â  Â  Â  if "Client" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ“Š Approval vs Denial Lead Age by Client")
Â  Â  Â  Â  Â  Â  grouped_client = pd.melt(
Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age,
Â  Â  Â  Â  Â  Â  Â  Â  id_vars=["Client"],
Â  Â  Â  Â  Â  Â  Â  Â  value_vars=["Lead Age (Approval)", "Lead Age (Denial)"],
Â  Â  Â  Â  Â  Â  Â  Â  var_name="Type",
Â  Â  Â  Â  Â  Â  Â  Â  value_name="Days"
Â  Â  Â  Â  Â  Â  ).dropna()
Â  Â Â 
Â  Â  Â  Â  Â  Â  chart_grouped_client = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(grouped_client)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x="Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="mean(Days)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Type",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Client", "Type", "mean(Days)"]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.altair_chart(chart_grouped_client, use_container_width=True)




Â  Â  # ================== DUPLICATES CHECK WITH PRODUCT ==================
Â  Â  st.subheader("ğŸ” Duplicate Leads by MCN (Considering Product)")
Â  Â Â 
Â  Â  if "MCN" in df_filtered.columns and "Products" in df_filtered.columns:
Â  Â  Â  Â  # --- Duplicates with same Product ---
Â  Â  Â  Â  dup_same_product = df_filtered[df_filtered.duplicated(subset=["MCN", "Products"], keep=False)]
Â  Â Â 
Â  Â  Â  Â  if not dup_same_product.empty:
Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {dup_same_product['MCN'].nunique()} unique MCNs duplicated with SAME Product "
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â f"(total {len(dup_same_product)} rows).")
Â  Â Â 
Â  Â  Â  Â  Â  Â  cols_to_show = [
Â  Â  Â  Â  Â  Â  Â  Â  "MCN","Products","Chaser Name","Chaser Group","Date of Sale (Date)","Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date (Date)","Approval date (Date)","Denial Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date (Date)","Upload Date (Date)","Client",
Â  Â  Â  Â  Â  Â  Â  Â  "Chasing Disposition","Insurance","Type Of Sale"
Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  available_cols = [c for c in cols_to_show if c in dup_same_product.columns]
Â  Â Â 
Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“‹ View Duplicate Leads (Same Product)"):
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dup_same_product.sort_values(["MCN", "Products"])[available_cols],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“Š Group by MCN + key dates
Â  Â  Â  Â  Â  Â  if all(c in dup_same_product.columns for c in ["Upload Date (Date)", "Completion Date (Date)", "Assigned date (Date)"]):
Â  Â  Â  Â  Â  Â  Â  Â  grouped_same = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  dup_same_product.groupby(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ["MCN", "Products", "Upload Date (Date)", "Completion Date (Date)", "Assigned date (Date)"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ).size().reset_index(name="Count")
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ“Š Duplicate MCN (Same Product) Grouped by Key Dates")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(grouped_same.sort_values("Count", ascending=False), use_container_width=True)
Â  Â Â 
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.success("âœ… No duplicate MCNs found with SAME product.")
Â  Â Â 
Â  Â  Â  Â  # --- Duplicates with different Product ---
Â  Â  Â  Â  dup_diff_product = (
Â  Â  Â  Â  Â  Â  df_filtered[df_filtered.duplicated(subset=["MCN"], keep=False)]
Â  Â  Â  Â  Â  Â  .drop_duplicates(subset=["MCN", "Products"])
Â  Â  Â  Â  )
Â  Â Â 
Â  Â  Â  Â  dup_diff_product_grouped = dup_diff_product.groupby("MCN")["Products"].nunique().reset_index()
Â  Â  Â  Â  dup_diff_product_grouped = dup_diff_product_grouped[dup_diff_product_grouped["Products"] > 1]
Â  Â Â 
Â  Â  Â  Â  if not dup_diff_product_grouped.empty:
Â  Â  Â  Â  Â  Â  st.info(f"â„¹ï¸ Found {len(dup_diff_product_grouped)} MCNs with DIFFERENT Products (not real dups).")
Â  Â Â 
Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“‹ View MCNs with Different Products"):
Â  Â  Â  Â  Â  Â  Â  Â  merged = dup_diff_product.merge(dup_diff_product_grouped[["MCN"]], on="MCN")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  merged.sort_values(["MCN", "Products"])[available_cols],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â Â 
Â  Â  else:
Â  Â  Â  Â  st.info("â„¹ï¸ Columns **MCN** and/or **Products** not found in dataset.")

Â  Â Â 
Â  Â Â 



































Ø´ÙˆÙ Ø§Ù„ÙƒÙˆØ¯ Ø¯Ù‡ ÙƒØ¯Ù‡ 
