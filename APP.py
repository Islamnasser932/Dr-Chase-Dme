import streamlit as st
import pandas as pd
import altair as alt
import re
from streamlit_option_menu import option_menu
from streamlit_extras.metric_cards import style_metric_cards
import mathÂ 

# ================== PAGE CONFIG ==================
st.set_page_config(
Â  Â  page_title="DR Chase Leads Dashboard",
Â  Â  page_icon="ğŸ“Š",
Â  Â  layout="wide",
Â  Â  initial_sidebar_state="expanded"
)

# ================== HELPER FUNCTIONS ==================
def norm(s: str) -> str:
Â  Â  return re.sub(r'[^a-z0-9]+', '', str(s).strip().lower())

def find_col(df_cols, candidates):
Â  Â  cand_norm = {norm(c) for c in candidates}
Â  Â  for c in df_cols:
Â  Â  Â  Â  if norm(c) in cand_norm:
Â  Â  Â  Â  Â  Â  return c
Â  Â  return None

def categorize_weeks(days):
Â  Â  if pd.isna(days):
Â  Â  Â  Â  return None
Â  Â  if days >= 0:
Â  Â  Â  Â  return f"Week {math.floor(days / 7) + 1}"
Â  Â  else:
Â  Â  Â  Â  return f"Week {math.ceil(days / 7)}"Â 

# ================== SYNONYMS & MAPS ==================
syn = {
Â  Â  "created_time": ["created_time", "created time", "creation time", "created", "lead created", "request created"],
Â  Â  "assign_date": ["assign_date", "assigned date", "assign time", "assigned time", "assigned on"],
Â  Â  "approval_date": ["approval_date", "approved date", "approval time", "approved on"],
Â  Â  "completion_date": ["completion_date", "completed date", "completion time", "closed date", "completed on"],
Â  Â  "uploaded_date": ["uploaded_date", "upload date", "uploaded date", "uploaded on"],
Â  Â  "assigned_to_chase": ["assigned to chase", "assigned_to_chase", "assigned to", "assigned user (chase)", "assigned chaser"],
}

name_map = {
Â  Â  "a.williams": "Alfred Williams", "david.smith": "David Smith", "jimmy.daves": "Grayson Saint",
Â  Â  "e.moore": "Eddie Moore", "aurora.stevens": "Aurora Stevens", "grayson.saint": "Grayson Saint",
Â  Â  "emma.wilson": "Emma Wilson", "scarlett.mitchell": "Scarlett Mitchell", "lucas.diago": "Lucas Diago",
Â  Â  "mia.alaxendar": "Mia Alaxendar", "ivy.brooks": "Ivy Brooks", "timothy.williams": "Timothy Williams",
Â  Â  "sarah.adams": "Sarah Adams", "sara.adams": "Sarah Adams", "samy.youssef": "Samy Youssef",
Â  Â  "candy.johns": "Candy Johns", "heather.robertson": "Heather Robertson", "a.cabello": "Andrew Cabello",
Â  Â  "alia.scott": "Alia Scott", "sandra.sebastian": "Sandra Sebastian", "kayla.miller": "Kayla Miller"
}

samy_chasers = {
Â  Â  "Emma Wilson", "Scarlett Mitchell", "Lucas Diago", "Mia Alaxendar",
Â  Â  "Candy Johns", "Sandra Sebastian", "Alia Scott",
Â  Â  "Ivy Brooks", "Heather Robertson", "Samy Youssef",
Â  Â  "Sarah Adams", "Timothy Williams"
}

# âš ï¸ Load Raw Data (Initial Check)
try:
Â  Â  df_raw = pd.read_csv("Dr_Chase_Leads.csv", low_memory=False)
except FileNotFoundError:
Â  Â  st.error("âš ï¸ Ø®Ø·Ø£: Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ù…Ù„Ù 'Dr_Chase_Leads.csv'. ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„Ù ÙÙŠ Ù†ÙØ³ Ø§Ù„Ù…Ø¬Ù„Ø¯.")
Â  Â  st.stop()
df_raw.columns = df_raw.columns.str.strip()

cols_map = {
Â  Â  "created_time": find_col(df_raw.columns, syn["created_time"]),
Â  Â  "assign_date": find_col(df_raw.columns, syn["assign_date"]),
Â  Â  "approval_date": find_col(df_raw.columns, syn["approval_date"]),
Â  Â  "completion_date": find_col(df_raw.columns, syn["completion_date"]),
Â  Â  "uploaded_date": find_col(df_raw.columns, syn["uploaded_date"]),
Â  Â  "assigned_to_chase": find_col(df_raw.columns, syn["assigned_to_chase"]),
}

# ================== DATA CLEANING & CACHING FUNCTION ==================
@st.cache_data
def load_and_clean_data(df, name_map, cols_map, samy_chasers):
Â  Â  df_cleaned = df.copy()
Â  Â Â 
Â  Â  # 1. Remove columns
Â  Â  columns_to_remove = [
Â  Â  Â  Â  "Is Converted From Lead", "Height", "Weight", "Waist Size", "Dr Phone Number", "Dr Fax",
Â  Â  Â  Â  "Dr Alternative Phone", "Dr Address", "Dr City", "Dr ZIP Code", "NPI", "Dr Info Extra Comments",
Â  Â  Â  Â  "Dr. Name", "Exception", "Initial Agent", "Full Name", "Last Name", "Secondary Phone", "Address",
Â  Â  Â  Â  "Gender", "ZIP Code", "City", "Phase","First Name","LOMN?","Source","Brace Size","Extra Comments" ,"CBA","Primary Phone"
Â  Â  ]
Â  Â  df_cleaned = df_cleaned.drop(columns=[c for c in columns_to_remove if c in df_cleaned.columns], errors="ignore")

Â  Â  # 2. Date Conversion
Â  Â  date_columns_original = [
Â  Â  Â  Â  "Created Time", "Assigned date", "Completion Date", "Approval date",
Â  Â  Â  Â  "Denial Date", "Modified Time", "Date of Sale", "Upload Date",Â 
Â  Â  ]

Â  Â  for col in date_columns_original:
Â  Â  Â  Â  if col in df_cleaned.columns:
Â  Â  Â  Â  Â  Â  # Convert to datetime (day first format is assumed: DD/MM/YYYY)
Â  Â  Â  Â  Â  Â  df_cleaned[col] = pd.to_datetime(
Â  Â  Â  Â  Â  Â  Â  Â  df_cleaned[col],Â 
Â  Â  Â  Â  Â  Â  Â  Â  errors="coerce",Â 
Â  Â  Â  Â  Â  Â  Â  Â  dayfirst=True,Â 
Â  Â  Â  Â  Â  Â  Â  Â  infer_datetime_format=True
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # Create additional split columns for date/time (used for st.dataframe)
Â  Â  Â  Â  Â  Â  df_cleaned[col + " (Date)"] = df_cleaned[col].dt.date
Â  Â  Â  Â  Â  Â  if df_cleaned[col].dt.time.notna().any():
Â  Â  Â  Â  Â  Â  Â  Â  Â df_cleaned[col + " (Time)"] = df_cleaned[col].dt.time

Â  Â  # 3. Chaser Name Mapping and Grouping
Â  Â  assigned_col = cols_map["assigned_to_chase"]
Â  Â  if assigned_col and assigned_col in df_cleaned.columns:
Â  Â  Â  Â  df_cleaned["Chaser Name"] = (
Â  Â  Â  Â  Â  Â  df_cleaned[assigned_col]
Â  Â  Â  Â  Â  Â  .astype(str).str.strip().str.lower()
Â  Â  Â  Â  Â  Â  .map(name_map)
Â  Â  Â  Â  Â  Â  .fillna(df_cleaned[assigned_col])
Â  Â  Â  Â  )
Â  Â  Â  Â  df_cleaned["Chaser Group"] = df_cleaned["Chaser Name"].apply(
Â  Â  Â  Â  Â  Â  lambda n: "Samy Chasers" if n in samy_chasers else "Andrew Chasers"
Â  Â  Â  Â  )
Â  Â Â 
Â  Â  # 4. Ensure core columns used for calculation are datetime
Â  Â  date_actual_cols = [cols_map[k] for k in ["created_time","assign_date","approval_date","completion_date","uploaded_date"] if cols_map[k]]
Â  Â  for c in date_actual_cols:
Â  Â  Â  Â  Â if c in df_cleaned.columns:
Â  Â  Â  Â  Â  Â  df_cleaned[c] = pd.to_datetime(df_cleaned[c], errors="coerce")

Â  Â  return df_cleaned

# ================== EXECUTE DATA LOAD ==================
df_cleaned = load_and_clean_data(df_raw, name_map, cols_map, samy_chasers)
st.success("âœ… File loaded and cleaned successfully! (Cached for speed)")

# ================== COLUMN DESCRIPTIONS ==================
column_descriptions = {
Â  Â  "Assigned To Chase": "Username of the chaser assigned to the lead (mapped later to full names).",
Â  Â  "Dr Chase Lead Number": "Unique ID assigned to each lead in the DR Chase system.",
Â  Â  "Created Time": "Timestamp when the lead was first created.",
Â  Â  "Modified Time": "Timestamp of the most recent modification.",
Â  Â  "Source": "Where the lead originated (e.g., CRM, referral, etc.).",
Â  Â  "Brace Size": "Medical brace size requested or required (e.g., Small, Medium, Large).",
Â  Â  "Extra Comments": "Additional notes about the lead, such as waist size or doctor instructions.",
Â  Â  "Dr Name": "Name of the doctor associated with the lead.",
Â  Â  "Dr State": "State where the doctor is located.",
Â  Â  "Dr Specialty": "Doctorâ€™s medical specialty (e.g., Internal Medicine, Orthopedics).",
Â  Â  "Confirmation Call Type": "Type of call used to confirm details (e.g., Doctor Call, Patient Call).",
Â  Â  "Closer Name": "Agent responsible for closing the lead.",
Â  Â  "Team Leader": "Team Leader supervising the chaser/closer.",
Â  Â  "L Codes": "Medical billing or insurance codes associated with the product (e.g., L1852).",
Â  Â  "Client": "Client associated with the lead (e.g., PPO-Braces chasing).",
Â  Â  "CBA": "Zipcode classification or market quality indicator (e.g., Good Zipcode).",
Â  Â  "Validator": "Agent responsible for validating the lead details.",
Â  Â  "Validation": "Validation status of the lead (e.g., Valid, Invalid).",
Â  Â  "Next Follow-up Date": "Planned date for the next follow-up.",
Â  Â  "Follow Up Attempts": "Number of follow-up attempts made.",
Â  Â  "Validation Comments": "Notes left by validators during validation checks.",
Â  Â  "Chasing Disposition": "Final chasing result (e.g., Dead Lead, Successful Chase).",
Â  Â  "Type Of Sale": "Category of the lead (e.g., Normal Chase, Red Flag).",
Â  Â  "Why is it a red chase?": "Explanation for red chase categorization.",
Â  Â  "Supervisor": "Supervisor responsible for overseeing the team.",
Â  Â  "Initial Status Received On": "First status received from doctorâ€™s office or patient (e.g., Pending Fax).",
Â  Â  "Dr Office DB Updated?": "Whether the doctor office database was updated (Yes/No).",
Â  Â  "Pharmacy Name": "Pharmacy involved in the case (if applicable).",
Â  Â  "Completion Date": "Date when the lead was completed/closed.",
Â  Â  "CN?": "Indicates whether a CN (Certificate of Necessity) is present (Yes/No).",
Â  Â  "QA Agent": "Quality Assurance agent who checked the case.",
Â  Â  "Uploaded?": "Whether the required documents were uploaded (Yes/No).",
Â  Â  "Upload Date": "Date when documents were uploaded.",
Â  Â  "QA Comments": "Feedback or notes from QA agent.",
Â  Â  "Approval date": "Date when the lead was approved.",
Â  Â  "Denial Date": "Date when the lead was denied (if applicable).",
Â  Â  "Assigned date": "Date the lead was assigned to a chaser.",
Â  Â  "Days Spent As Pending QA": "Number of days lead stayed in Pending QA status.",
Â  Â  "Primary Phone": "Patientâ€™s primary phone number.",
Â  Â  "Date of Birth": "Patientâ€™s date of birth.",
Â  Â  "Date of Sale": "Date when the sale was confirmed.",
Â  Â  "Insurance": "Type of insurance associated with the lead (e.g., PPO).",
Â  Â  "MCN": "Medical Case Number associated with the patient/lead.",
Â  Â  "PPO ID -If any-": "Insurance PPO ID if available.",
Â  Â  "Products": "Products linked to the lead (e.g., braces, medical items).",
Â  Â  "State": "Patientâ€™s state of residence.",
Â  Â  "Chasing Comments": "Additional notes from chasers about follow-ups.",
Â  Â  "Primary Insurance": "Primary insurance provider (e.g., Medicare).",
Â  Â  "Last Modified By": "User who last modified the lead record.",
Â  Â  "Chaser Name": "Mapped name of the chaser assigned to the lead.",
Â  Â  "Chaser Group": "Group classification (e.g., Samy Chasers, Andrew Chasers)."
}


# ================== SIDEBAR MENU ==================
with st.sidebar:
Â  Â  selected = option_menu(
Â  Â  Â  Â  menu_title="Main Menu",
Â  Â  Â  Â  options=["Dataset Overview", "Data Analysis"],
Â  Â  Â  Â  icons=["table", "bar-chart"],
Â  Â  Â  Â  menu_icon="cast",
Â  Â  Â  Â  default_index=0,
Â  Â  Â  Â  orientation="vertical"
Â  Â  )

# --- Function for tabular view (USED IN BOTH TABS) ---
def table(df_filtered):
Â  Â  with st.expander("ğŸ“Š Tabular Data View"):
Â  Â  Â  Â  default_cols = [
Â  Â  Â  Â  Â  Â  "MCN","Chaser Name","Chaser Group","Date of Sale (Date)","Created Time (Date)","Assigned date (Date)",
Â  Â  Â  Â  Â  Â  "Approval date (Date)","Denial Date (Date)","Completion Date (Date)",
Â  Â  Â  Â  Â  Â  "Upload Date (Date)","Client","Chasing Disposition","Insurance","Type Of Sale","Products"
Â  Â  Â  Â  ]
Â  Â  Â  Â  shwdata_defaults = [c for c in default_cols if c in df_filtered.columns]

Â  Â  Â  Â  shwdata = st.multiselect(
Â  Â  Â  Â  Â  Â  "Filter Columns:",
Â  Â  Â  Â  Â  Â  df_filtered.columns.tolist(),
Â  Â  Â  Â  Â  Â  default=shwdata_defaults
Â  Â  Â  Â  )
Â  Â  Â  Â  st.dataframe(df_filtered[shwdata], use_container_width=True)


# ================== SIDEBAR FILTERS ==================
st.sidebar.header("ğŸ› Basic Filters")

# --- Client Filter ---
with st.sidebar.expander("ğŸ‘¥ Client", expanded=False):
Â  Â  all_clients = df_cleaned["Client"].unique().tolist()
Â  Â  select_all_clients = st.checkbox("Select All Clients", value=True, key="all_clients")
Â  Â  if select_all_clients:
Â  Â  Â  Â  Client = st.multiselect("Select Client", options=all_clients, default=all_clients)
Â  Â  else:
Â  Â  Â  Â  Client = st.multiselect("Select Client", options=all_clients)


# --- Chaser Name Filter ---
with st.sidebar.expander("ğŸ§‘â€ğŸ’¼ Chaser Name", expanded=False):
Â  Â  all_Chaser_Name=df_cleaned["Chaser Name"].unique().tolist()
Â  Â  select_all_Chaser_Name = st.checkbox("Select All Chaser Name ", value=True, key="all_Chaser_Name")
Â  Â  if select_all_Chaser_Name:
Â  Â  Â  Â  Chaser_Name = st.multiselect("Select Chaser Name", options=all_Chaser_Name, default=all_Chaser_Name)Â  Â 
Â  Â  else:
Â  Â  Â  Â  Chaser_NameÂ  = st.multiselect("SelectÂ  Chaser Name ", options=all_Chaser_Name)
Â  Â  Â  Â  Â  Â Â 

# --- Chaser Group Filter ---
with st.sidebar.expander("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Chaser Group", expanded=False):
Â  Â  all_Chaser_Group=df_cleaned["Chaser Group"].unique().tolist()
Â  Â  select_all_Chaser_Group = st.checkbox("Select All Chaser Group ", value=True, key="all_Chaser_Group")
Â  Â  if select_all_Chaser_Group:
Â  Â  Â  Â  Chaser_Group = st.multiselect("Select Chaser Group", options=all_Chaser_Group, default=all_Chaser_Group)Â  Â 
Â  Â  else:
Â  Â  Â  Â  Chaser_GroupÂ  = st.multiselect("SelectÂ  Chaser Group ", options=all_Chaser_Group)


# --- Chasing Disposition Filter ---
with st.sidebar.expander("ğŸ‘¥ Chasing Disposition", expanded=False):
Â  Â  all_Chasing_Disposition=df_cleaned["Chasing Disposition"].unique().tolist()
Â  Â  select_all_Chasing_Disposition = st.checkbox("Select All Chaser Disposition ", value=True, key="all_Chasing_Disposition")
Â  Â  if select_all_Chasing_Disposition:
Â  Â  Â  Â  Chasing_Disposition = st.multiselect("Select Chaser Disposition", options=all_Chasing_Disposition, default=all_Chasing_Disposition)Â  Â 
Â  Â  else:
Â  Â  Â  Â  Chasing_DispositionÂ  = st.multiselect("SelectÂ  Chaser Disposition ", options=all_Chasing_Disposition)


# --- Date Range Filter ---
with st.sidebar.expander("ğŸ“… Date Range", expanded=False):
Â  Â  date_cols_for_range = [
Â  Â  Â  Â  "Created Time", "Assigned date", "Completion Date", "Approval date",
Â  Â  Â  Â  "Denial Date", "Modified Time", "Date of Sale", "Upload Date"
Â  Â  ]
Â  Â Â 
Â  Â  valid_date_cols = [c for c in date_cols_for_range if c in df_cleaned.columns]
Â  Â Â 
Â  Â  date_range = None
Â  Â  if valid_date_cols:
Â  Â  Â  Â  all_dates = pd.concat([df_cleaned[c].dropna() for c in valid_date_cols])
Â  Â  Â  Â Â 
Â  Â  Â  Â  if not all_dates.empty:
Â  Â  Â  Â  Â  Â  min_ts = all_dates.min()
Â  Â  Â  Â  Â  Â  max_ts = all_dates.max()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  min_date = min_ts.date()
Â  Â  Â  Â  Â  Â  max_date = max_ts.date()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  date_range = st.date_input(
Â  Â  Â  Â  Â  Â  Â  Â  "Select date range (based on Available Dates)",
Â  Â  Â  Â  Â  Â  Â  Â  value=(min_date, max_date),
Â  Â  Â  Â  Â  Â  Â  Â  min_value=min_date,
Â  Â  Â  Â  Â  Â  Â  Â  max_value=max_date
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.warning("No valid dates found in the dataset.")
Â  Â  Â  Â  Â  Â  default_date = pd.Timestamp.now().date()
Â  Â  Â  Â  Â  Â  date_range = (default_date, default_date)
Â  Â  Â  Â  Â  Â  st.date_input("Select date range (No Data Available)", value=date_range, disabled=True)
Â  Â  else:
Â  Â  Â  Â  st.warning("No date columns found for filtering.")
Â  Â  Â  Â  default_date = pd.Timestamp.now().date()
Â  Â  Â  Â  date_range = (default_date, default_date)


# --- Apply filters using .query() ---
df_filtered = df_cleaned.query(
Â  Â  "Client in @Client and `Chaser Name` in @Chaser_Name and `Chaser Group` in @Chaser_Group and `Chasing Disposition` in @Chasing_Disposition"
)

# Apply date filter (on Created Time by default)
if isinstance(date_range, tuple) and len(date_range) == 2:
Â  Â  start_date, end_date = date_range
Â  Â  if "Created Time" in df_filtered.columns:
Â  Â  Â  Â  df_filtered = df_filtered[
Â  Â  Â  Â  Â  Â  (df_filtered["Created Time"].dt.date >= start_date)
Â  Â  Â  Â  Â  Â  & (df_filtered["Created Time"].dt.date <= end_date)
Â  Â  Â  Â  ]

# ================== MAIN DASHBOARD (Dataset Overview) ==================
if selected == "Dataset Overview":
Â  Â  st.title("ğŸ“‹ Dataset Overview â€“ General Inspection")
Â  Â  st.info("This page is for **quick inspection** of the dataset, showing key metrics, summaries, and descriptions of columns.")

Â  Â  st.subheader("ğŸ” Data Inspection")
Â  Â  st.markdown(f""" The dataset contains **{len(df_filtered)} rows**
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â and **{len(df_filtered.columns)} columns**.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â """)
Â  Â  table(df_filtered)

Â  Â  # --- KPIs Section ---
Â  Â  st.subheader("ğŸ“Œ Key Performance Indicators")
Â  Â Â 
    # --- ğŸ”½ğŸ”½ğŸ”½ START OF EDITED SECTION ğŸ”½ğŸ”½ğŸ”½ ---
Â  Â  # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ù‚ÙŠÙ… ---
Â  Â  total_leads = len(df_filtered)
Â  Â  total_completed = df_filtered["Completion Date"].notna().sum() if "Completion Date" in df_filtered.columns else 0
Â  Â  total_assigned = df_filtered["Assigned date"].notna().sum() if "Assigned date" in df_filtered.columns else 0
Â  Â  total_uploaded = df_filtered["Upload Date"].notna().sum() if "Upload Date" in df_filtered.columns else 0
Â  Â  total_approval = df_filtered["Approval date"].notna().sum() if "Approval date" in df_filtered.columns else 0
Â  Â  total_denial = df_filtered["Denial Date"].notna().sum() if "Denial Date" in df_filtered.columns else 0
Â  Â Â 
    # ğŸ†• (Ø¬Ø¯ÙŠØ¯) Ø­Ø³Ø§Ø¨ Ø§Ù„Ù€ Pending Shipping
    if "Chasing Disposition" in df_filtered.columns:
        total_pending_shipping = df_filtered[
            df_filtered["Chasing Disposition"].astype(str).str.lower() == "pending shipping"
        ].shape[0]
    else:
        total_pending_shipping = 0

Â  Â  # Derived metrics
Â  Â  total_not_assigned = total_leads - total_assigned
Â  Â Â 
Â  Â  # Percentages
Â  Â  pct_completed = (total_completed / total_leads * 100) if total_leads > 0 else 0
Â  Â  pct_assigned = (total_assigned / total_leads * 100) if total_leads > 0 else 0
Â  Â  pct_not_assigned = (total_not_assigned / total_leads * 100) if total_leads > 0 else 0
    # âš ï¸ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ù†ÙØ³ Ø§Ù„Ù…Ù†Ø·Ù‚: Uploaded ÙƒÙ†Ø³Ø¨Ø© Ù…Ù† Completed
Â  Â  pct_uploaded = (total_uploaded / total_completed * 100) if total_completed > 0 else 0
Â  Â  pct_approval = (total_approval / total_leads * 100) if total_leads > 0 else 0
Â  Â  pct_denial = (total_denial / total_leads * 100) if total_leads > 0 else 0
    # ğŸ†• (Ø¬Ø¯ÙŠØ¯) Ù†Ø³Ø¨Ø© Ø§Ù„Ù€ Pending Shipping Ù…Ù† Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ
    pct_pending_shipping = (total_pending_shipping / total_leads * 100) if total_leads > 0 else 0
Â  Â Â 
Â  Â  # --- ğŸ†• (ØªØ¹Ø¯ÙŠÙ„) KPIs Layout (8 Ø¨Ø·Ø§Ù‚Ø§Øª) ---
Â  Â  col1, col2, col3 = st.columns(3)
Â  Â  col4, col5, col6 = st.columns(3)
    col7, col8 = st.columns(2) # ğŸ†• ØµÙ Ø¬Ø¯ÙŠØ¯
Â  Â Â 
Â  Â  with col1:
Â  Â  Â  Â  st.metric("ğŸ“Š Total Leads", f"{total_leads:,}")
Â  Â  with col2:
Â  Â  Â  Â  st.metric("ğŸ§‘â€ğŸ’¼ Assigned", f"{total_assigned:,} ({pct_assigned:.1f}%)")
Â  Â  with col3:
Â  Â  Â  Â  st.metric("ğŸš« Not Assigned", f"{total_not_assigned:,} ({pct_not_assigned:.1f}%)") # Ù†Ù‚Ù„Ù†Ø§Ù‡Ø§ Ù‡Ù†Ø§
Â  Â  with col4:
Â  Â  Â  Â  st.metric("âœ… Completed", f"{total_completed:,} ({pct_completed:.1f}%)")
Â  Â  with col5:
Â  Â  Â  Â  # ğŸ†• (ØªØ¹Ø¯ÙŠÙ„) Approved ÙÙŠ Ø¨Ø·Ø§Ù‚Ø© Ù…Ù†ÙØµÙ„Ø©
Â  Â  Â  Â  st.metric("âœ” Approved", f"{total_approval:,} ({pct_approval:.1f}%)")
Â  Â  with col6:
Â  Â  Â  Â  # ğŸ†• (ØªØ¹Ø¯ÙŠÙ„) Denied ÙÙŠ Ø¨Ø·Ø§Ù‚Ø© Ù…Ù†ÙØµÙ„Ø©
Â  Â  Â  Â  st.metric("âŒ Denied", f"{total_denial:,} ({pct_denial:.1f}%)")
Â  Â  with col7:
Â  Â  Â  Â  # ğŸ’¡ Ù…Ù„Ø­ÙˆØ¸Ø©: Ø§Ù„Ù†Ø³Ø¨Ø© Ù‡Ù†Ø§ Ù…Ù† Ø§Ù„Ù€ Completed ÙƒÙ…Ø§ ÙÙŠ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø£ØµÙ„ÙŠ
Â  Â  Â  Â  st.metric("ğŸ“¤ Uploaded", f"{total_uploaded:,} ({pct_uploaded:.1f}%)")
Â  Â  with col8:
Â  Â  Â  Â  # ğŸ†• (Ø¬Ø¯ÙŠØ¯) Ø¨Ø·Ø§Ù‚Ø© Ø§Ù„Ù€ Pending Shipping
Â  Â  Â  Â  st.metric("ğŸšš Total Upload to Client (Pending Shipping)", 
Â  Â  Â  Â  Â  Â  Â  Â   f"{total_pending_shipping:,} ({pct_pending_shipping:.1f}%)")
Â  Â  Â  Â Â 
Â  Â Â 
Â  Â  Â  Â  # âœ… Apply custom style
Â  Â  style_metric_cards(
Â  Â  Â  Â  background_color="#0E1117",Â  # Ø®Ù„ÙÙŠØ© dashboard ØºØ§Ù…Ù‚Ø©
Â  Â  Â  Â  border_left_color="#00BFFF",Â  # Ø£Ø²Ø±Ù‚ Ù„Ù„Ù€ Total
Â  Â  Â  Â  border_color="#444",
Â  Â  Â  Â  box_shadow="2px 2px 10px rgba(0,0,0,0.5)"
Â  Â  )
Â  Â  Â  Â Â 
    # --- ğŸ”¼ğŸ”¼ğŸ”¼ END OF EDITED SECTION ğŸ”¼ğŸ”¼ğŸ”¼ ---
Â  Â Â 
Â  Â Â 
Â  Â  # --- Dates summary (table) ---
Â  Â  date_cols = df_filtered.select_dtypes(include=["datetime64[ns]"]).columns
Â  Â  if len(date_cols) > 0:
Â  Â  Â  Â  st.markdown("### ğŸ“… Date Ranges in Dataset")
Â  Â  Â  Â  date_summary = pd.DataFrame({
Â  Â  Â  Â  Â  Â  "Column": date_cols,
Â  Â  Â  Â  Â  Â  "First Date": [df_filtered[c].min() for c in date_cols],
Â  Â  Â  Â  Â  Â  "Last Date": [df_filtered[c].max() for c in date_cols],
Â  Â  Â  Â  })
Â  Â  Â  Â  st.table(date_summary)


Â  Â  # --- Numeric summary (table) ---
Â  Â  num_cols = df_filtered.select_dtypes(include=["int64", "float64"]).columns
Â  Â  if len(num_cols) > 0:
Â  Â  Â  Â  st.markdown("### ğŸ”¢ Numeric Columns Summary")
Â  Â  Â  Â  num_summary = pd.DataFrame({
Â  Â  Â  Â  Â  Â  "Column": num_cols,
Â  Â  Â  Â  Â  Â  "Min": [df_filtered[c].min() for c in num_cols],
Â  Â  Â  Â  Â  Â  "Max": [df_filtered[c].max() for c in num_cols],
Â  Â  Â  Â  Â  Â  "Mean": [round(df_filtered[c].mean(), 2) for c in num_cols]
Â  Â  Â  Â  })
Â  Â  Â  Â  st.table(num_summary)

Â  Â  # --- Column Descriptions ---
Â  Â  st.subheader("ğŸ“– Column Descriptions")
Â  Â  st.info("Choose a column to see what it represents and explore its distribution.")

Â  Â  Â  Â  # âœ… Restrict to specific columns
Â  Â  description_columns = [
Â  Â  Â  Â  "Chaser Name", "Chaser Group", "Date of Sale (Date)", "Created Time (Date)",
Â  Â  Â  Â  "Assigned date (Date)", "Approval date (Date)", "Denial Date (Date)",
Â  Â  Â  Â  "Completion Date (Date)", "Upload Date (Date)", "Client",
Â  Â  Â  Â  "Chasing Disposition", "Insurance", "Type Of Sale", "Products","Days Spent As Pending QA"
Â  Â  ]

Â  Â  # Keep only the ones that exist in df_cleaned
Â  Â  valid_desc_cols = [c for c in description_columns if c in df_cleaned.columns]

Â  Â  selected_col = st.selectbox(
Â  Â  Â  Â  "Select a column to view description",
Â  Â  Â  Â  valid_desc_cols
Â  Â  )

Â  Â  desc = column_descriptions.get(selected_col, "No description available for this column.")
Â  Â Â 

Â  Â  # --- Force date conversion for known date columns ---
Â  Â  date_columns_for_vis = [
Â  Â  Â  Â  "Date of Sale (Date)", "Created Time (Date)", "Assigned date (Date)",
Â  Â  Â  Â  "Approval date (Date)", "Denial Date (Date)",
Â  Â  Â  Â  "Completion Date (Date)", "Upload Date (Date)"
Â  Â  ]

Â  Â  for col in date_columns_for_vis:
Â  Â  Â  Â  if col in df_filtered.columns:
Â  Â  Â  Â  Â  Â  df_filtered[col] = pd.to_datetime(df_filtered[col], errors="coerce")

Â  Â  # --- Extra Visualization (same logic you already have) ---
Â  Â  if selected_col in df_filtered.select_dtypes(include=["object"]).columns:
Â  Â  Â  Â  st.markdown(f"### ğŸ“Š Distribution of {selected_col}")
Â  Â  Â  Â  chart_data = df_filtered[selected_col].value_counts().reset_index()
Â  Â  Â  Â  chart_data.columns = [selected_col, "Count"]

Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  alt.Chart(chart_data)
Â  Â  Â  Â  Â  Â  .mark_bar(color="#16eff7")
Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X(selected_col, sort="-y"),
Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[selected_col, "Count"]
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)

Â  Â  elif selected_col in df_filtered.select_dtypes(include=["number"]).columns:
Â  Â  Â  Â  st.markdown(f"### ğŸ“Š Distribution of {selected_col}")

Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  alt.Chart(df_filtered)
Â  Â  Â  Â  Â  Â  .mark_bar(color="#0eff87")
Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X(selected_col, bin=alt.Bin(maxbins=30)),Â  # bins for histogram
Â  Â  Â  Â  Â  Â  Â  Â  y='count()',
Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[selected_col, "count()"]
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)




Â  Â  elif selected_col in df_filtered.select_dtypes(include=["datetime64[ns]"]).columns:
Â  Â  Â  Â  st.markdown(f"### ğŸ“ˆ Time Series of {selected_col}")
Â  Â  Â  Â  ts_data = df_filtered[selected_col].value_counts().reset_index()
Â  Â  Â  Â  ts_data.columns = [selected_col, "Count"]
Â  Â  Â  Â  ts_data = ts_data.sort_values(selected_col)

Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  alt.Chart(ts_data)
Â  Â  Â  Â  Â  Â  .mark_line(point=True, color="#ff7f0e")
Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  x=selected_col,
Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  tooltip=[selected_col, "Count"]
Â  Â  	 Â  Â  )
Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)


# ================== MAIN DASHBOARD (Data Analysis) ==================
elif selected == "Data Analysis":
Â  Â  st.title("ğŸ“Š Data Analysis â€“ Advanced Insights")
Â  Â  st.info("This page provides **deeper analysis** including time-series trends, insights summaries, and lead age analysis by Chaser / Client.")

Â  Â  # --- Allowed columns for analysis ---
Â  Â  allowed_columns = [
Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  "Assigned date (Date)",
Â  Â  Â  Â  "Approval date (Date)",
Â  Â  Â  Â  "Denial Date (Date)",
Â  Â  Â  Â  "Completion Date (Date)",
Â  Â  Â  Â  "Upload Date (Date)",
Â  Â  Â  Â  "Date of Sale (Date)",
Â  Â  ]
Â  Â Â 
Â  Â  # Keep only available ones from dataset
Â  Â  available_columns = [c for c in allowed_columns if c in df_filtered.columns]
Â  Â Â 
Â  Â  if not available_columns:
Â  Â  Â  Â  st.warning("âš ï¸ None of the predefined analysis columns are available in the dataset.")
Â  Â  Â  Â  st.stop()
Â  Â  Â  Â Â 
Â  Â  time_col = st.selectbox("Select column for analysis", available_columns)
Â  Â  original_time_col = time_col.replace(" (Date)", "") # e.g., 'Created Time'
Â  Â Â 
Â  Â  # Prepare df_ts
Â  Â  df_ts = df_filtered.copy()
Â  Â  if original_time_col in df_ts.columns:
Â  Â  Â  Â  df_ts = df_ts[df_ts[original_time_col].notna()].copy()

Â  Â  Â  Â  today = pd.Timestamp.now().normalize()
Â  Â  Â  Â  future_mask = df_ts[original_time_col].dt.normalize() > today
Â  Â  Â  Â  df_ts = df_ts.loc[~future_mask].copy()

Â  Â  st.markdown(f""" The working dataset for analysis contains **{len(df_ts)} rows**
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â and **{len(df_ts.columns)} columns**.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â """)
Â  Â  table(df_filtered) # Use df_filtered for the general table view

Â  Â  Â  Â  Â  Â Â 
Â  Â  total_leads = len(df_filtered)
Â  Â Â 
Â  Â  # --- Aggregation frequency ---
Â  Â  freq = st.radio("Aggregation level:", ["Daily", "Weekly", "Monthly"], horizontal=True)
Â  Â  period_map = {"Daily": "D", "Weekly": "W", "Monthly": "M"}
Â  Â Â 
Â  Â  if original_time_col in df_ts.columns:
Â  Â  Â  Â  df_ts["Period"] = df_ts[original_time_col].dt.to_period(period_map[freq]).dt.to_timestamp()
Â  Â  else:
Â  Â  Â  Â  # Fallback: cannot proceed with time series
Â  Â  Â  Â  df_ts = pd.DataFrame()Â 

Â  Â  # --- Grouping option ---
Â  Â  group_by = st.selectbox("Break down by:", ["None", "Client", "Chaser Name", "Chaser Group"])
Â  Â  if group_by == "None":
Â  Â  Â  Â  ts_data = df_ts.groupby("Period").size().reset_index(name="Lead Count")
Â  Â  else:
Â  Â  Â  Â  ts_data = df_ts.groupby(["Period", group_by]).size().reset_index(name="Lead Count")

Â  Â  if not ts_data.empty:
Â  Â  Â  Â  # ğŸ“ˆ Historical Time Series
Â  Â  Â  Â  st.subheader("ğŸ“ˆ Historical Time Series")

Â  Â  Â  Â  if group_by == "None":
Â  Â  Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(ts_data)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_line(point=True, color="#007bff")
Â  Â  Â  Â  Â  Â  Â  Â  .encode(x="Period:T", y="Lead Count", tooltip=["Period:T", "Lead Count"])
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  chart = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(ts_data)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_line(point=True)
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x="Period:T",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Lead Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=group_by,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Period:T", "Lead Count", group_by]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  st.altair_chart(chart, use_container_width=True)


Â  Â  Â  Â  # ğŸ† Top performers
Â  Â  Â  Â  if group_by in ["Chaser Name", "Client"]:
Â  Â  Â  Â  Â  Â  st.subheader(f"ğŸ† Top {group_by}s by Leads")
Â  Â  Â  Â  Â  Â  top_table = ts_data.groupby(group_by)["Lead Count"].sum().reset_index()
Â  Â  Â  Â  Â  Â  top_table = top_table.sort_values("Lead Count", ascending=False).head(40)
Â  Â  Â  Â  Â  Â  st.table(top_table)
Â  Â  Â  Â Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  # ================== Chasing Disposition Distribution (MODIFIED: Compact Metric) ==================
Â  Â  Â  Â  if "Chasing Disposition" in df_ts.columns:
Â  Â  Â  Â  Â  Â  st.subheader("ğŸ“Š Chasing Disposition Distribution")

Â  Â  Â  Â  Â  Â  # --- Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø§Ù„Ù„ÙŠ Ù†Ø¹Ø±Ø¶Ù‡Ø§ ---
Â  Â  Â  Â  Â  Â  metric_options_disp = [
Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded"
Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  metric_option = st.selectbox(
Â  Â  Â  Â  Â  Â  Â  Â  "Select metric to display by Chasing Disposition:",
Â  Â  Â  Â  Â  Â  Â  Â  metric_options_disp
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø­Ø³Ø¨ ÙƒÙ„ Chasing Disposition ---
Â  Â  Â  Â  Â  Â  metrics_by_disp = df_ts.groupby("Chasing Disposition").agg({
Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)": "count",
Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Approval date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  }).reset_index()

Â  Â  Â  Â  Â  Â  metrics_by_disp["Not Assigned"] = (
Â  Â  Â  Â  Â  Â  Â  Â  metrics_by_disp["Created Time (Date)"] - metrics_by_disp["Assigned date"]
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # --- Ø±Ø¨Ø· Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø¨Ø§Ù„Ø§Ø¹Ù…Ø¯Ø© ---
Â  Â  Â  Â  Â  Â  metric_map = {
Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))": "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned": "Assigned date",
Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned": "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved": "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied": "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed": "Completion Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded": "Upload Date"
Â  Â  Â  Â  Â  Â  }

Â  Â  Â  Â  Â  Â  selected_col = metric_map[metric_option]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø¬Ù‡Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
Â  Â  Â  Â  Â  Â  chart_data = metrics_by_disp[["Chasing Disposition", selected_col]].rename(columns={selected_col: "Count"})

Â  Â  Â  Â  Â  Â  # âœ… Ø¥Ø¶Ø§ÙØ© Ù…Ø¤Ø´Ø± Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„ÙŠ ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø¶ÙŠÙ‚
Â  Â  Â  Â  Â  Â  total_selected_metric = chart_data["Count"].sum()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“Œ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù„ØªØµØºÙŠØ± Ø­Ø¬Ù… Ø§Ù„Ù…Ø¤Ø´Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
Â  Â  Â  Â  Â  Â  col_metric, col_spacer = st.columns([1, 4]) # 1:4 ratio for small metric and large spacer
Â  Â  Â  Â  Â  Â  with col_metric:
Â  Â  Â  Â  Â  Â  Â  Â  st.metric(label=f"Total Count for: {metric_option}", value=f"{total_selected_metric:,}")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # âœ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© ÙˆØªØ³Ù…ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Label)
Â  Â  Â  Â  Â  Â  total_for_percentage = total_selected_metric
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if total_for_percentage > 0:
Â  Â  Â  Â  Â  Â  Â  Â  chart_data["Percentage"] = (chart_data["Count"] / total_for_percentage * 100).round(1)
Â  Â  Â  Â  Â  Â  Â  Â  chart_data["Label"] = chart_data["Count"].apply(lambda x: f'{x:,}')Â 
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  chart_data["Percentage"] = 0.0
Â  Â  Â  Â  Â  Â  Â  Â  chart_data["Label"] = chart_data["Count"].apply(lambda x: f'{x:,}')


Â  Â  Â  Â  Â  Â  # --- Bar chart ---
Â  Â  Â  Â  Â  Â  chart_disp = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(chart_data)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Chasing Disposition", sort="-y", title="Chasing Disposition"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y=alt.Y("Count", title=selected_col.replace(" (Date)", "")),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Chasing Disposition",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Chasing Disposition", "Count", alt.Tooltip("Percentage", format=".1f", title="Percentage (%)")]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Text Layer (Data Label) ---
Â  Â  Â  Â  Â  Â  text = chart_disp.mark_text(
Â  Â  Â  Â  Â  Â  Â  Â  align='center',Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  baseline='bottom',Â 
Â  Â  Â  Â  Â  Â  Â  Â  dy=-5,Â  Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  Â  Â  Â  Â  color='white',Â  Â  Â 
Â  Â  Â  Â  Â  Â  Â  Â  fontSize=12
Â  Â  Â  Â  Â  Â  ).encode(
Â  Â  Â  Â  Â  Â  Â  Â  text=alt.Text("Label")Â 
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # --- Final Chart ---
Â  Â  Â  Â  Â  Â  final_chart = chart_disp + text
Â  Â  Â  Â  Â  Â  st.altair_chart(final_chart, use_container_width=True)


Â  Â  Â  Â  Â  Â  # ================== Client Distribution (MODIFIED: Compact Metric) ==================
Â  Â  Â  Â  if "Client" in df_ts.columns:
Â  Â  Â  Â  Â  Â  st.subheader("ğŸ‘¥ Client Distribution")
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø§Ù„Ù„ÙŠ Ù†Ø¹Ø±Ø¶Ù‡Ø§ ---
Â  Â  Â  Â  Â  Â  metric_options_client = [
Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded"
Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  metric_option_client = st.selectbox(
Â  Â  Â  Â  Â  Â  Â  Â  "Select metric to display by Client:",
Â  Â  Â  Â  Â  Â  Â  Â  metric_options_client,
Â  Â  Â  Â  Â  Â  Â  Â  key="client_metric"
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…ØªØ±ÙƒØ³ Ø­Ø³Ø¨ ÙƒÙ„ Client ---
Â  Â  Â  Â  Â  Â  metrics_by_client = df_ts.groupby("Client").agg({
Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)": "count",
Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Approval date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date": lambda x: x.notna().sum(),
Ã‚ Â  Â  Â  Â  Â  Â  Â  "Completion Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date": lambda x: x.notna().sum(),
Â  Â  Â  Â  Â  Â  }).reset_index()
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  metrics_by_client["Not Assigned"] = metrics_by_client["Created Time (Date)"] - metrics_by_client["Assigned date"]
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø±Ø¨Ø· Ø§Ù„Ø§Ø®ØªÙŠØ§Ø±Ø§Øª Ø¨Ø§Ù„Ø§Ø¹Ù…Ø¯Ø© ---
Â  Â  Â  Â  Â  Â  metric_map = {
Â  Â  Â  Â  Â  Â  Â  Â  "Total Leads (with Created Time (Date))": "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Assigned": "Assigned date",
Â  Â  Â  Â  Â  Â  Â  Â  "Not Assigned": "Not Assigned",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Approved": "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Denied": "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Completed": "Completion Date",
Â  Â  Â  Â  Â  Â  Â  Â  "Total Uploaded": "Upload Date"
Â  Â  Â  Â  Â  Â  }
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  selected_col_client = metric_map[metric_option_client]
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Ø¬Ù‡Ø² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
Â  Â  Â  Â  Â  Â  chart_data_client = metrics_by_client[["Client", selected_col_client]].rename(columns={selected_col_client: "Count"})

Â  Â  Â  Â  Â  Â  # âœ… Ø¥Ø¶Ø§ÙØ© Ù…Ø¤Ø´Ø± Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„ÙŠ ÙÙŠ Ø¹Ù…ÙˆØ¯ Ø¶ÙŠÙ‚
Â  Â  Â  Â  Â  Â  total_selected_metric_client = chart_data_client["Count"].sum()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“Œ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„ Ù„ØªØµØºÙŠØ± Ø­Ø¬Ù… Ø§Ù„Ù…Ø¤Ø´Ø± Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø©
Â  Â  Â  Â  Â  Â  col_metric_client, col_spacer_client = st.columns([1, 4])Â 
Â  Â  Â  Â  Â  Â  with col_metric_client:
Â  Â  Â  Â  Â  Â  Â  Â  st.metric(label=f"Total Count for: {metric_option_client}", value=f"{total_selected_metric_client:,}")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # âœ… Ø­Ø³Ø§Ø¨ Ø§Ù„Ù†Ø³Ø¨Ø© Ø§Ù„Ù…Ø¦ÙˆÙŠØ© ÙˆØªØ³Ù…ÙŠØ© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Data Label)
Â  Â  Â  Â  Â  Â  total_for_percentage_client = total_selected_metric_client
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if total_for_percentage_client > 0:
Â  Â  Â  Â  Â  Â  Â  Â  chart_data_client["Percentage"] = (chart_data_client["Count"] / total_for_percentage_client * 100).round(1)
Â  Â  Â  Â  Â  Â  Â  Â  chart_data_client["Label"] = chart_data_client["Count"].apply(lambda x: f'{x:,}')Â 
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  chart_data_client["Percentage"] = 0.0
Â  Â  Â  Â  Â  Â  Â  Â  chart_data_client["Label"] = chart_data_client["Count"].apply(lambda x: f'{x:,}')
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Bar chart ---
Â  Â  Â  Â  Â  Â  chart_disp_client = (
Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(chart_data_client)
Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Client", sort="-y"),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y=alt.Y("Count", title=selected_col_client.replace(" (Date)", "")),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Client", "Count", alt.Tooltip("Percentage", format=".1f", title="Percentage (%)")]
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  .properties(height=400)
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  Â  Â  # --- Text Layer (Data Label) ---
Â  Â  Â  Â  Â  Â  text_client = chart_disp_client.mark_text(
Â  Â  Â  Â  Â  Â  Â  Â  align='center',Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  baseline='bottom',Â 
Â  Â  Â  Â  Â  Â  Â  Â  dy=-5,Â  Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  Â  Â  Â  Â  color='white',Â  Â  Â 
Â  Â  Â  Â  Â  Â  Â  Â  fontSize=12
Â  Â  Â  Â  Â  Â  ).encode(
Â  Â  Â  Â  Â  Â  Â  Â  text=alt.Text("Label")Â 
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  final_chart_client = chart_disp_client + text_client
Â  Â  Â  Â  Â  Â  st.altair_chart(final_chart_client, use_container_width=True)

Â  Â  Â  Â  # ğŸ“ Insights Summary
Â  Â  Â  Â  st.subheader("ğŸ“ Insights Summary")
Â  Â  Â  Â Â 
Â  Â  Â  Â  df_time = df_ts[df_ts[original_time_col].notna()].copy()
Â  Â  Â  Â  total_time_leads = len(df_time)
Â  Â  Â  Â Â 
Â  Â  Â  Â  st.write(f"Based on **{time_col}**, there are **{total_time_leads} leads** with this date.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if total_time_leads > 0:
Â  Â  Â  Â  Â  Â  total_assigned = df_time["Assigned date"].notna().sum() if "Assigned date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_not_assigned = total_time_leads - total_assigned
Â  Â  Â  Â  Â  Â  total_approval = df_time["Approval date"].notna().sum() if "Approval date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_denial = df_time["Denial Date"].notna().sum() if "Denial Date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_uploaded = df_time["Upload Date"].notna().sum() if "Upload Date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â  total_completed = df_time["Completion Date"].notna().sum() if "Completion Date" in df_time.columns else 0
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Show stats
Â  Â  Â  Â  Â  Â  st.markdown(f"""
Â  Â  Â  Â  Â  Â  Â  Â  - âœ… Total Leads (with {time_col}): **{total_time_leads}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸ§‘â€ğŸ’¼ Assigned: **{total_assigned}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸš« Not Assigned: **{total_not_assigned}**
Â  Â  Â  Â  Â  Â  Â  Â  - âœ” Approved: **{total_approval}**
Â  Â  Â  Â  Â  Â  Â  Â  - âŒ Denied: **{total_denial}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸ“Œ Completed: **{total_completed}**
Â  Â  Â  Â  Â  Â  Â  Â  - ğŸ“¤ Uploaded: **{total_uploaded}**
Â  Â  Â  Â  Â  Â  Â  Â  """)Â  Â  Â  Â  Â 
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.subheader("ğŸš¨ Data Quality Warnings")
Â  Â  Â  Â  Â  Â  today = pd.Timestamp.now().normalize()


Â  Â  Â  Â  Â  Â  # ğŸš¨ Leads with Pending Shipping but no Upload Date
Â  Â  Â  Â  Â  Â  if "Chasing Disposition" in df_filtered.columns and "Upload Date" in df_filtered.columns:
Â  Â  Â  Â  Â  Â  Â  Â  mask_shipping = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_filtered["Chasing Disposition"].astype(str).str.lower().eq("pending shipping")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  & df_filtered["Upload Date"].isna()
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  pending_shipping = df_filtered[mask_shipping]
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if not pending_shipping.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(pending_shipping)} leads with **Pending Shipping** but missing **Upload Date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Pending Shipping Leads Without Upload Date"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pending_shipping[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chasing Disposition",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸš¨ Leads pending too long (Fax / Dr Call)
Â  Â  Â  Â  Â  Â  if "Created Time (Date)" in df_filtered.columns and "Chasing Disposition" in df_filtered.columns:
Â  Â  Â  Â  Â  Â  Â  Â  today = pd.Timestamp.now().normalize()
Â  Â  Â  Â  Â  Â  Â  Â s
Â  Â  Â  Â  Â  Â  Â  Â  df_filtered["Days Since Created"] = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  today - pd.to_datetime(df_filtered["Created Time (Date)"], errors="coerce")
Â  Â  Â  Â  Â  Â  Â  Â  ).dt.days
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  pending_mask = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (df_filtered["Days Since Created"] > 7) &
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (df_filtered["Chasing Disposition"].isin(["Pending Fax", "Pending Dr Call"]))
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  pending_leads = df_filtered[pending_mask]
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  if not pending_leads.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(pending_leads)} leads pending for more than 7 days (Fax/Dr Call).")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Pending Leads > 7 Days"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  pending_leads[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN",
source
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Days Since Created",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chasing Disposition",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Upload Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date (Date)",
Note
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )


Â  Â  Â  Â  Â  Â  # --- Row-level logic checks with expanders ---
Â  Â  Â  Â  Â  Â  if "Completion Date" in df_time.columns and "Assigned date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_rows = df_time[df_time["Completion Date"].notna() & df_time["Assigned date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_rows.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_rows)} leads with **Completion Date** but no **Assigned date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Assigned Date"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_rows[["MCN", "Client", "Chaser Name", "Created Time", "Assigned date", "Completion Date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  DÂ  Â  )
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if "Completion Date" in df_time.columns and "Approval date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_rows2 = df_time[df_time["Completion Date"].notna() & df_time["Approval date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_rows2.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_rows2)} leads with **Completion Date** but no **Approval date**.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Approval Date"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_rows2[["MCN", "Client", "Chaser Name", "Created Time", "Approval date", "Completion Date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Extra checks for Uploaded Date ---
Â  Â  Â  Â  Â  Â  if "Upload Date" in df_time.columns and "Completion Date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded = df_time[df_time["Upload Date"].notna() & df_time["Completion Date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_uploaded.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_uploaded)} leads with **Upload Date** but no **Completion Date**.")
IÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Completion Date after Upload"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded[["MCN", "Client", "Chaser Name", "Upload Date", "Completion Date"]],
DÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if "Upload Date" in df_time.columns and "Assigned date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_assigned = df_time[df_time["Upload Date"].notna() & df_time["Assigned date"].isna()]
SourceÂ  Â  Â  Â  Â  Â  Â  Â  if not bad_uploaded_assigned.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_uploaded_assigned)} leads with **Upload Date** but no **Assigned date**.")
SeeÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Assigned Date after Upload"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_assigned[["MCN", "Client", "Chaser Name", "Upload Date", "Assigned date"]],
SecurityÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if "Upload Date" in df_time.columns and "Approval date" in df_time.columns:
Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_approval = df_time[df_time["Upload Date"].notna() & df_time["Approval date"].isna()]
Â  Â  Â  Â  Â  Â  Â  Â  if not bad_uploaded_approval.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(bad_uploaded_approval)} leads with **Upload Date** but no **Approval date**.")
sÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads Missing Approval Date after Upload"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  bad_uploaded_approval[["MCN", "Client", "Chaser Name", "Upload Date", "Approval date"]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )


Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ================== Lead Age Analysis ==================
Â  Â  Â  Â  st.subheader("â³ Lead Age Analysis")
Â  Â  Â  Â  st.info("Analysis of how long it takes for leads to get Approved / Denied. Includes weekly distribution, averages/medians, and grouped comparisons.")
Note
Â  Â  Â  Â Â 
Â  Â  Â  Â  if "Created Time" in df_ts.columns:
Â  Â  Â  Â  Â  Â  df_lead_age = df_ts.copy()
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Ø­Ø³Ø§Ø¨ Lead Age Ù…Ù† Approval Ùˆ Denial
Â  Â  Â  Â  Â  Â  if "Approval date" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Lead Age (Approval)"] = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (df_lead_age["Approval date"] - df_lead_age["Created Time"]).dt.days
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  if "Denial Date" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Lead Age (Denial)"] = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  (df_lead_age["Denial Date"] - df_lead_age["Created Time"]).dt.days
NoteÂ  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- KPIs Section ---
Â  Â  Â  Â  Â  Â  total_approved = df_lead_age["Approval date"].notna().sum()
Â  Â  Â  Â  Â  Â  total_denied = df_lead_age["Denial Date"].notna().sum()
Â  Â  Â  Â  Â  Â  avg_approval_age = df_lead_age["Lead Age (Approval)"].mean(skipna=True)
CÂ  Â  Â  Â  Â  Â  avg_denial_age = df_lead_age["Lead Age (Denial)"].mean(skipna=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  col1, col2, col3, col4 = st.columns(4)
Â  Â  Â  Â  Â  Â  with col1:
Â  Â  Â  Â  Â  Â  Â  Â  st.metric("âœ”ï¸ Total Approved", f"{total_approved:,}")
CÂ  Â  Â  Â  Â  Â  with col2:
Â  Â  Â  Â  Â  Â  Â  Â  st.metric("âŒ Total Denied", f"{total_denied:,}")
Â  Â  Â  Â  Â  Â  with col3:
Â  Â  Â  Â  Â  Â  Â  Â  st.metric("â³ Avg Approval Age", f"{avg_approval_age:.1f} days" if not pd.isna(avg_approval_age) else "N/A")
NoteÂ  Â  Â  Â  Â  Â  with col4:
Â  Â  Â  Â  Â  Â  Â  Â  st.metric("â³ Avg Denial Age", f"{avg_denial_age:.1f} days" if not pd.isna(avg_denial_age) else "N/A")
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  style_metric_cards(
Â  Â  Â  Â  Â  Â  Â  Â  background_color="#0E1117",
Â  Â  Â  Â  Â  Â  Â  Â  border_left_color={
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "âœ”ï¸ Total Approved": "#28a745",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "âŒ Total Denied": "#dc3545",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "â³ Avg Approval Age": "#17a2b8",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "â³ Avg Denial Age": "#ffc107",
Â  Â  Â  Â  Â  Â  _ Â  },
Â  Â  Â  Â  Â  Â  Â  Â  border_color="#444",
Â  Â  Â  Â  Â  Â  Â  Â  box_shadow="2px 2px 10px rgba(0,0,0,0.5)"
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“‹ Full Lead Age Table (hidden by default)
Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“‹ View Full Lead Age Table"):
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date",
source
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Approval)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Denial)",
Note
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
NoteÂ  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸš¨ Check for leads with both Approval & Denial
Â  Â  Â  Â  Â  Â  both_dates = df_lead_age[df_lead_age["Approval date"].notna() & df_lead_age["Denial Date"].notna()]
Â  Â  Â  Â  Â  Â  if not both_dates.empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(both_dates)} leads with BOTH Approval & Denial dates. Please review.")
Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ” View Leads with BOTH Approval & Denial"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  cols_to_show = [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time (Date)",
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Approval)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Denial)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
IndentedÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  available_cols = [c for c in cols_to_show if c in both_dates.columns]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(both_dates[available_cols], use_container_width=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“Š Lead Age Distribution â€“ Approval
Â  Â  Â  Â  Â  Â  if "Lead Age (Approval)" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“Š Lead Age Distribution â€“ Approval"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Approval Category"] = df_lead_age["Lead Age (Approval)"].dropna().apply(categorize_weeks)
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  categories = df_lead_age["Approval Category"].dropna().unique()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  weeks_negative = sorted([c for c in categories if "Week -" in c], key=lambda x: int(x.split()[1]))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  weeks_positive = sorted([c for c in categories if "Week " in c and "-" not in c], key=lambda x: int(x.split()[1]))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  category_order = weeks_negative + weeks_positive
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  approval_summary = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Approval Category"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .value_counts()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reindex(category_order)
DÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reset_index()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  approval_summary.columns = ["Category", "Count"]
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  approval_summary["Color"] = approval_summary["Category"].apply(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lambda x: "#FFA500" if "Week -" in x else "#28a745"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  chart_approval = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(approval_summary)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Category", sort=category_order),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=alt.Color("Color:N", scale=None, legend=None),
IndentedÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Category", "Count"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.altair_chart(chart_approval, use_container_width=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ø¬Ø¯ÙˆÙ„ leads ÙÙŠ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø³Ø§Ù„Ø¨Ø© - Approval
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if "Approval Category" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_approval = df_lead_age[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Approval Category"].astype(str).str.contains("Week -", na=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not negative_approval.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(negative_approval)} approvals with negative week categories.")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_approval[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval date",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Approval)",
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Approval Category",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“Š Lead Age Distribution â€“ Denial
Â  Â  Â  Â  Â  Â  if "Lead Age (Denial)" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“Š Lead Age Distribution â€“ Denial"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Denial Category"] = df_lead_age["Lead Age (Denial)"].dropna().apply(categorize_weeks)
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  categories = df_lead_age["Denial Category"].dropna().unique()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  weeks_negative = sorted([c for c in categories if "Week -" in c], key=lambda x: int(x.split()[1]))
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  weeks_positive = sorted([c for c in categories if "Week " in c and "-" not in c], key=lambda x: int(x.split()[1]))
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  category_order = weeks_negative + weeks_positive
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  denial_summary = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age["Denial Category"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .value_counts()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reindex(category_order)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .reset_index()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  denial_summary.columns = ["Category", "Count"]
IndentedÂ  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  denial_summary["Color"] = denial_summary["Category"].apply(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  lambda x: "#FFA500" if "Week -" in x else "#dc3545"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  chart_denial = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(denial_summary)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x=alt.X("Category", sort=category_order),
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="Count",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color=alt.Color("Color:N", scale=None, legend=None),
Â  Â  Â  Â  Â  Â  Â  Â  Â  _ Â  Â  Â  Â  tooltip=["Category", "Count"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  content
Â  Â  Â  Â  Â  Â  Â  Â  st.altair_chart(chart_denial, use_container_width=True)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ø¬Ø¯ÙˆÙ„ leads ÙÙŠ Ø§Ù„Ø£Ø³Ø§Ø¨ÙŠØ¹ Ø§Ù„Ø³Ø§Ù„Ø¨Ø© - Denial
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if "Denial Category" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_denial = df_lead_age[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  D Â  Â  Â  df_lead_age["Denial Category"].astype(str).str.contains("Week -", na=False)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not negative_denial.empty:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {len(negative_denial)} denials with negative week categories.")
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  negative_denial[[
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Date",
IndentedÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Lead Age (Denial)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Denial Category",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“Š Grouped Bar Chart â€“ Approval vs Denial per Chaser
Â  Â  Â  Â  Â  Â  if "Chaser Name" in df_lead_age.columns:
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ“Š Approval vs Denial Lead Age by Chaser")
NoteÂ  Â  Â  Â  Â  Â  Â  Â  grouped_chaser = pd.melt(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  id_vars=["Chaser Name"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value_vars=["Lead Age (Approval)", "Lead Age (Denial)"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var_name="Type",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value_name="Days"
NoteÂ  Â  Â  Â  Â  Â  Â  Â  ).dropna()
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  chart_grouped_chaser = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(grouped_chaser)
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x="Chaser Name",
DÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="mean(Days)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Type",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Chaser Name", "Type", "mean(Days)"]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.altair_chart(chart_grouped_chaser, use_container_width=True)
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ğŸ“Š Grouped Bar Chart â€“ Approval vs Denial per Client
Â  Â  Â  Â  Â  Â  if "Client" in df_lead_age.columns:
Â  Â  NoteÂ  Â  Â  Â  Â  st.markdown("### ğŸ“Š Approval vs Denial Lead Age by Client")
Â  Â  Â  Â  Â  Â  Â  Â  grouped_client = pd.melt(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  df_lead_age,
Ã‚ Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  id_vars=["Client"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value_vars=["Lead Age (Approval)", "Lead Age (Denial)"],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  var_name="Type",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value_name="Days"
Â  Â  Â  Â  Â  Â  Â  Â  ).dropna()
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  chart_grouped_client = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  alt.Chart(grouped_client)
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  .mark_bar()
Â  NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  .encode(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  x="Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  y="mean(Days)",
sourceÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  color="Type",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  tooltip=["Client", "Type", "mean(Days)"]
sÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  st.altair_chart(chart_grouped_client, use_container_width=True)


Â  Â  Â  Â Â 
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # ================== DUPLICATES CHECK WITH PRODUCT (MODIFIED: Removed Grouped by Key Dates) ==================
IndentedÂ  Â  Â  Â  st.subheader("ğŸ” Duplicate Leads by MCN (Considering Product)")
Â  Â  Â  Â Â 
Â  Â  Â  Â  if "MCN" in df_filtered.columns and "Products" in df_filtered.columns:
Â  Â  Â  Â  Â  Â  # --- Duplicates with same MCN and same Product ---
Â  Â  Â  Â  Â  Â  dup_same_product = df_filtered[df_filtered.duplicated(subset=["MCN", "Products"], keep=False)].copy()
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if not dup_same_product.empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.warning(f"âš ï¸ Found {dup_same_product['MCN'].nunique()} unique MCNs duplicated with SAME Product "
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â f"(total {len(dup_same_product)} rows).")
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # âœ… Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
Â  Â  Â  Â  Â  Â  Â  Â  required_cols = [
Â  Â  Â  contentÂ  Â  Â  Â  Â  Â  Â  Â  "MCN",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Products",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Created Time",Note
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Date of Sale",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Dr Name",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Client",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chaser Name",Â 
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chasing Disposition"
Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # ØªØµÙÙŠØ© Ø§Ù„Ø£Ø¹Ù…Ø¯Ø© Ø§Ù„Ù…ØªÙˆÙØ±Ø© ÙÙ‚Ø·
NoteÂ  Â  Â  Â  Â  Â  Â  Â  available_dup_cols = [c for c in required_cols if c in dup_same_product.columns]
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # **Ø§Ù„Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: Duplicate Leads (MCN & Product) Details**
Â  Â  Â  Â  Â  Â  Â  Â  st.markdown("### ğŸ“‹ Duplicate Leads (MCN & Product) Details")
Â  Â  Â  Â  Â  Â  Â  Â  st.dataframe(
Â  Â  Â  s Â  Â  Â  Â  Â  Â  Â  dup_same_product.sort_values(["MCN", "Products", "Created Time"])[available_dup_cols],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  # ğŸ“Œ ØªÙ… Ø­Ø°Ù Ø§Ù„Ø¬Ø¯ÙˆÙ„: "ğŸ“Š Duplicate MCN (Same Product) Grouped by Key Dates"source
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  st.success("âœ… No duplicate MCNs found with SAME product.")
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # --- Duplicates with different Product ---
Â  Â  Â  Â  Â  Â  dup_diff_product_check = df_filtered[df_filtered.duplicated(subset=["MCN"], keep=False)].copy()
NoteÂ  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Filter to only MCNs that truly have different products
Â  Â  Â  Â  Â  Â  dup_diff_product_grouped = dup_diff_product_check.groupby("MCN")["Products"].nunique().reset_index()
Â  Â  Â  Â  Â  Â  mcn_with_diff_products = dup_diff_product_grouped[dup_diff_product_grouped["Products"] > 1]["MCN"]

Â  Â  Â  Â  Â  Â  dup_diff_product = dup_diff_product_check[dup_diff_product_check["MCN"].isin(mcn_with_diff_products)].copy()
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if not dup_diff_product.empty:
Â  Â  Â  Â  Â  Â  Â  Â  st.info(f"â„¹ï¸ Found {len(mcn_with_diff_products)} MCNs with DIFFERENT Products (not real dups).")
Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  Â  Â  with st.expander("ğŸ“‹ View MCNs with Different Products"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â cols_to_show_old = [
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "MCN","Products","Chaser Name","Chaser Group","Date of Sale (Date)","Created Time (Date)",
NoteÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Assigned date (Date)","Approval date (Date)","Denial Date (Date)",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Completion Date (Date)","Upload Date (Date)","Client",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Chasing Disposition","Insurance","Type Of Sale"
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ]
Â  Â  Â  Â  Â  Â  Â  Â  Â  T Â  Â available_cols_for_diff_dups = [c for c in cols_to_show_old if c in dup_diff_product.columns]
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â 
Â  Â  Â  Â  Â  Â  Â  Â  Type Â  Â  Â  merged = dup_diff_product.merge(dup_diff_product_grouped[["MCN"]], on="MCN")
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â st.dataframe(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  merged.sort_values(["MCN", "Products"])[available_cols_for_diff_dups],
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  s Â  Â  Â  Â  )
Â  Â  Â  Â Â 
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.info("â„¹ï¸ Columns **MCN** and/or **Products** not found in dataset.")
